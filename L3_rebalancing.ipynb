{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 환경 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. 환경 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. 기본 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "from textwrap import dedent\n",
    "from pprint import pprint\n",
    "\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import uuid\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option('display.max_rows', 30)\n",
    "pd.set_option('display.max_columns', 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "타겟 자산명 (직접 작성)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_names = ['AA-ETF_EQUITY-XLU']\n",
    "# asset_names = ['AA-ETF_EQUITY-XLK', 'AA-ETF_EQUITY-XLE', 'AA-ETF_EQUITY-XLF', 'AA-ETF_EQUITY-XLV', 'AA-ETF_EQUITY-XLP', 'AA-ETF_EQUITY-XLI', 'AA-ETF_EQUITY-XLU']\n",
    "# asset_names = ['AA-ETF_EQUITY-EWY', 'AA-ETF_EQUITY-VWO', 'AA-ETF_EQUITY-EWC', 'AA-ETF_EQUITY-EFA', 'AA-ETF_EQUITY-EWJ', 'AA-ETF_EQUITY-EPP']\n",
    "# asset_names = ['AA-ETF_EQUITY-ACWV', 'AA-ETF_EQUITY-SUSL', 'AA-ETF_EQUITY-SCHD', 'AA-ETF_EQUITY-VYMI', 'AA-ETF_EQUITY-VTV'] # ['AA-ETF_EQUITY-ACWV.K', 'AA-ETF_EQUITY-SUSL.O', 'AA-ETF_EQUITY-SCHD.K', 'AA-ETF_EQUITY-VYMI.O', 'AA-ETF_EQUITY-VTV']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. 자산배분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BAS_DT</th>\n",
       "      <th>ASET_GRP</th>\n",
       "      <th>ASET_GRP_WGT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-11-20</td>\n",
       "      <td>AA-ETF_BOND-BND</td>\n",
       "      <td>0.0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-11-20</td>\n",
       "      <td>AA-ETF_BOND-BNDX</td>\n",
       "      <td>0.0011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-11-20</td>\n",
       "      <td>AA-ETF_EQUITY-ACWV</td>\n",
       "      <td>0.0030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-11-20</td>\n",
       "      <td>AA-ETF_EQUITY-EFA</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-11-20</td>\n",
       "      <td>AA-ETF_EQUITY-EPP</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>2024-12-17</td>\n",
       "      <td>AA-ETF_EQUITY-XLK</td>\n",
       "      <td>0.4481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>2024-12-17</td>\n",
       "      <td>AA-ETF_EQUITY-XLP</td>\n",
       "      <td>0.0103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>2024-12-17</td>\n",
       "      <td>AA-ETF_EQUITY-XLU</td>\n",
       "      <td>0.0145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>2024-12-17</td>\n",
       "      <td>AA-ETF_EQUITY-XLV</td>\n",
       "      <td>0.0099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>2024-12-17</td>\n",
       "      <td>AA-ETF_SUB-CASH</td>\n",
       "      <td>0.1766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>460 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         BAS_DT            ASET_GRP  ASET_GRP_WGT\n",
       "0    2024-11-20     AA-ETF_BOND-BND        0.0004\n",
       "1    2024-11-20    AA-ETF_BOND-BNDX        0.0011\n",
       "2    2024-11-20  AA-ETF_EQUITY-ACWV        0.0030\n",
       "3    2024-11-20   AA-ETF_EQUITY-EFA        0.0005\n",
       "4    2024-11-20   AA-ETF_EQUITY-EPP        0.0003\n",
       "..          ...                 ...           ...\n",
       "455  2024-12-17   AA-ETF_EQUITY-XLK        0.4481\n",
       "456  2024-12-17   AA-ETF_EQUITY-XLP        0.0103\n",
       "457  2024-12-17   AA-ETF_EQUITY-XLU        0.0145\n",
       "458  2024-12-17   AA-ETF_EQUITY-XLV        0.0099\n",
       "459  2024-12-17     AA-ETF_SUB-CASH        0.1766\n",
       "\n",
       "[460 rows x 3 columns]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_alloc = pd.read_csv('data/alloc_basdt_241217.csv')\n",
    "df_alloc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. 설명력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BAS_DT</th>\n",
       "      <th>XAI_LEVEL_NM</th>\n",
       "      <th>ASET_LEVEL</th>\n",
       "      <th>RIC</th>\n",
       "      <th>VAR_NM</th>\n",
       "      <th>INFC_SCRE</th>\n",
       "      <th>INFC_RNK</th>\n",
       "      <th>INFC_DIR</th>\n",
       "      <th>ASET_GRP</th>\n",
       "      <th>ASET_GRP_WGT</th>\n",
       "      <th>TABLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-11-20</td>\n",
       "      <td>자산군</td>\n",
       "      <td>L3</td>\n",
       "      <td>MCU0</td>\n",
       "      <td>London Metal Exchange (LME)-Copper Grade A Cas...</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>AA-ETF_EQUITY-XLU</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>DSC105TH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-11-20</td>\n",
       "      <td>자산군</td>\n",
       "      <td>L3</td>\n",
       "      <td>EUR2M=</td>\n",
       "      <td>United States Dollar to Euro 2 Month Forward P...</td>\n",
       "      <td>0.19</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td>AA-ETF_EQUITY-XLU</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>DSC104TH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-11-20</td>\n",
       "      <td>자산군</td>\n",
       "      <td>L3</td>\n",
       "      <td>XAU=</td>\n",
       "      <td>Gold, USD FX Composite U United States Dollar ...</td>\n",
       "      <td>0.18</td>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "      <td>AA-ETF_EQUITY-XLU</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>DSC105TH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-11-20</td>\n",
       "      <td>자산군</td>\n",
       "      <td>L3</td>\n",
       "      <td>STXEc1</td>\n",
       "      <td>EUREX-DJ EURO STOXX 50 TRc1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>4</td>\n",
       "      <td>-</td>\n",
       "      <td>AA-ETF_EQUITY-XLU</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>DSC103TH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-11-20</td>\n",
       "      <td>자산군</td>\n",
       "      <td>L3</td>\n",
       "      <td>.FTSE</td>\n",
       "      <td>FTSE 100</td>\n",
       "      <td>0.14</td>\n",
       "      <td>5</td>\n",
       "      <td>-</td>\n",
       "      <td>AA-ETF_EQUITY-XLU</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>DSC101TH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>2024-12-17</td>\n",
       "      <td>자산군</td>\n",
       "      <td>L3</td>\n",
       "      <td>ESc1</td>\n",
       "      <td>CME-MINI S&amp;P 500 INDEX TRc1</td>\n",
       "      <td>0.61</td>\n",
       "      <td>5</td>\n",
       "      <td>-</td>\n",
       "      <td>AA-ETF_EQUITY-XLU</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>DSC103TH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>2024-12-17</td>\n",
       "      <td>자산군</td>\n",
       "      <td>L3</td>\n",
       "      <td>FCc1</td>\n",
       "      <td>CME-Feeder Cattle Composite TRC1</td>\n",
       "      <td>0.56</td>\n",
       "      <td>6</td>\n",
       "      <td>-</td>\n",
       "      <td>AA-ETF_EQUITY-XLU</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>DSC103TH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2024-12-17</td>\n",
       "      <td>자산군</td>\n",
       "      <td>L3</td>\n",
       "      <td>JNIc1</td>\n",
       "      <td>OSX-NIKKEI 225 INDEX TRc1</td>\n",
       "      <td>0.54</td>\n",
       "      <td>7</td>\n",
       "      <td>-</td>\n",
       "      <td>AA-ETF_EQUITY-XLU</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>DSC103TH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2024-12-17</td>\n",
       "      <td>자산군</td>\n",
       "      <td>L3</td>\n",
       "      <td>LSUc1</td>\n",
       "      <td>LIFFE-WHITE SUGAR TRc1</td>\n",
       "      <td>0.35</td>\n",
       "      <td>15</td>\n",
       "      <td>+</td>\n",
       "      <td>AA-ETF_EQUITY-XLU</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>DSC103TH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2024-12-17</td>\n",
       "      <td>자산군</td>\n",
       "      <td>L3</td>\n",
       "      <td>BZZc1</td>\n",
       "      <td>NYMEX - Brent Crude Oil LST Day TRC1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>20</td>\n",
       "      <td>+</td>\n",
       "      <td>AA-ETF_EQUITY-XLU</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>DSC103TH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         BAS_DT XAI_LEVEL_NM ASET_LEVEL     RIC  \\\n",
       "0    2024-11-20          자산군         L3    MCU0   \n",
       "1    2024-11-20          자산군         L3  EUR2M=   \n",
       "2    2024-11-20          자산군         L3    XAU=   \n",
       "3    2024-11-20          자산군         L3  STXEc1   \n",
       "4    2024-11-20          자산군         L3   .FTSE   \n",
       "..          ...          ...        ...     ...   \n",
       "194  2024-12-17          자산군         L3    ESc1   \n",
       "195  2024-12-17          자산군         L3    FCc1   \n",
       "196  2024-12-17          자산군         L3   JNIc1   \n",
       "197  2024-12-17          자산군         L3   LSUc1   \n",
       "198  2024-12-17          자산군         L3   BZZc1   \n",
       "\n",
       "                                                VAR_NM  INFC_SCRE  INFC_RNK  \\\n",
       "0    London Metal Exchange (LME)-Copper Grade A Cas...       0.32         1   \n",
       "1    United States Dollar to Euro 2 Month Forward P...       0.19         2   \n",
       "2    Gold, USD FX Composite U United States Dollar ...       0.18         3   \n",
       "3                          EUREX-DJ EURO STOXX 50 TRc1       0.15         4   \n",
       "4                                             FTSE 100       0.14         5   \n",
       "..                                                 ...        ...       ...   \n",
       "194                        CME-MINI S&P 500 INDEX TRc1       0.61         5   \n",
       "195                   CME-Feeder Cattle Composite TRC1       0.56         6   \n",
       "196                          OSX-NIKKEI 225 INDEX TRc1       0.54         7   \n",
       "197                             LIFFE-WHITE SUGAR TRc1       0.35        15   \n",
       "198               NYMEX - Brent Crude Oil LST Day TRC1       0.25        20   \n",
       "\n",
       "    INFC_DIR           ASET_GRP  ASET_GRP_WGT     TABLE  \n",
       "0          -  AA-ETF_EQUITY-XLU        0.0059  DSC105TH  \n",
       "1          -  AA-ETF_EQUITY-XLU        0.0059  DSC104TH  \n",
       "2          -  AA-ETF_EQUITY-XLU        0.0059  DSC105TH  \n",
       "3          -  AA-ETF_EQUITY-XLU        0.0059  DSC103TH  \n",
       "4          -  AA-ETF_EQUITY-XLU        0.0059  DSC101TH  \n",
       "..       ...                ...           ...       ...  \n",
       "194        -  AA-ETF_EQUITY-XLU        0.0145  DSC103TH  \n",
       "195        -  AA-ETF_EQUITY-XLU        0.0145  DSC103TH  \n",
       "196        -  AA-ETF_EQUITY-XLU        0.0145  DSC103TH  \n",
       "197        +  AA-ETF_EQUITY-XLU        0.0145  DSC103TH  \n",
       "198        +  AA-ETF_EQUITY-XLU        0.0145  DSC103TH  \n",
       "\n",
       "[199 rows x 11 columns]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 전처리\n",
    "df_infc = pd.read_csv('data/infc_basdt_241217.csv')\n",
    "df_infc['ASET_GRP'] = df_infc['ASET_LEVEL'].str[3:]\n",
    "df_infc['ASET_LEVEL'] = df_infc['ASET_LEVEL'].str[:2]\n",
    "df_infc = df_infc[df_infc['ASET_GRP'].isin(asset_names)] # RIC 중복 존재 (기간 통합, L1-L3)\n",
    "\n",
    "df_infc = df_infc.merge(df_alloc, on=['BAS_DT', 'ASET_GRP'], how='inner')\n",
    "# df_infc = df_infc[['BAS_DT', 'ASET_GRP', 'ASET_GRP_WGT', 'RIC', 'VAR_NM', 'INFC_DIR']]\n",
    "df_infc = df_infc.reset_index(drop=True)\n",
    "\n",
    "# 테이블명 추가\n",
    "df_var_map = pd.read_csv('data/var_table_mapping.csv')\n",
    "df_var_map = df_var_map[['RIC', 'TABLE']]\n",
    "df_var_map = df_var_map.drop_duplicates('RIC') # RIC 중복 제거 (필드만 다른 경우 존재)\n",
    "df_infc = df_infc.merge(df_var_map, on='RIC', how='inner')\n",
    "\n",
    "df_infc = df_infc.reset_index(drop=True)\n",
    "df_infc # 최종"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3. 기초 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 RIC (데이터 존재하는 것들만)\n",
    "RIC_101 = ['.AORD', '.BVSP', '.FTSE', '.KS11']\n",
    "RIC_102 = ['BR10YT=RR', 'BR3YT=RR', 'KR3YT=RR']\n",
    "RIC_103 = ['BZZc1', 'Cc1', 'ESc1', 'FCc1', 'HOc1', 'INDc1', 'JNIc1', 'LCc1', 'LSUc1', 'PAc1', 'PLc1', 'STXEc1']\n",
    "RIC_104 = ['EUR1M=', 'EUR2M=', 'JPY=']\n",
    "RIC_105 = ['MCU0', 'XAU=']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 변수 (데이터 존재하는 것들만)\n",
    "var_101 = [df_infc[df_infc['RIC'] == RIC_101[i]]['VAR_NM'].iloc[0] for i in range(len(RIC_101))]\n",
    "var_102 = [df_infc[df_infc['RIC'] == RIC_102[i]]['VAR_NM'].iloc[0] for i in range(len(RIC_102))]\n",
    "var_103 = [df_infc[df_infc['RIC'] == RIC_103[i]]['VAR_NM'].iloc[0] for i in range(len(RIC_103))]\n",
    "var_104 = [df_infc[df_infc['RIC'] == RIC_104[i]]['VAR_NM'].iloc[0] for i in range(len(RIC_104))]\n",
    "var_105 = [df_infc[df_infc['RIC'] == RIC_105[i]]['VAR_NM'].iloc[0] for i in range(len(RIC_105))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Equity and Volatility Indicators': ['Standard and Poors / ASX All Ordinaries Gold Open',\n",
       "  'BRAZIL BOVESPA',\n",
       "  'FTSE 100',\n",
       "  'Korea Stock Exchange Composite (KOSPI)'],\n",
       " 'Government Bond Yields': ['Refinitiv Brazil Government Benchmark Bid Yield 10 Years',\n",
       "  'Refinitiv Brazil Government Benchmark Bid Yield 3 Years',\n",
       "  'Refinitiv S Korea Government Benchmark Bid Yield 3 Years'],\n",
       " 'Commodities and Futures': ['NYMEX - Brent Crude Oil LST Day TRC1',\n",
       "  'Chicago Board of Trade (CBOT)-Corn Composite TRC1',\n",
       "  'CME-MINI S&P 500 INDEX TRc1',\n",
       "  'CME-Feeder Cattle Composite TRC1',\n",
       "  'NYM-NY HARBOR ULSD TRc1',\n",
       "  'BMF-BOVESPA INDEX TRc1',\n",
       "  'OSX-NIKKEI 225 INDEX TRc1',\n",
       "  'CME-LIVE CATTLE COMP. TRc1',\n",
       "  'LIFFE-WHITE SUGAR TRc1',\n",
       "  'NYM-PALLADIUM TRc1',\n",
       "  'NYM-PLATINUM TRc1',\n",
       "  'EUREX-DJ EURO STOXX 50 TRc1'],\n",
       " 'Currency Exchange Rates': ['United States Dollar to Euro 1 Month Forward Points',\n",
       "  'United States Dollar to Euro 2 Month Forward Points',\n",
       "  'Japanese Yen to United States Dollar (Refinitiv)'],\n",
       " 'Market Index': ['London Metal Exchange (LME)-Copper Grade A Cash United States Dollar Per Metric Tonne',\n",
       "  'Gold, USD FX Composite U United States Dollar Per Troy Ounce']}"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_dict = {\n",
    "    'Equity and Volatility Indicators': var_101,\n",
    "    'Government Bond Yields': var_102,\n",
    "    'Commodities and Futures': var_103,\n",
    "    'Currency Exchange Rates': var_104,\n",
    "    'Market Index': var_105\n",
    "    }\n",
    "var_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_dict_101 = dict(zip(RIC_101, var_101))\n",
    "var_dict_102 = dict(zip(RIC_102, var_102))\n",
    "var_dict_103 = dict(zip(RIC_103, var_103))\n",
    "var_dict_104 = dict(zip(RIC_104, var_104))\n",
    "var_dict_105 = dict(zip(RIC_105, var_105))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "   df_101 = pd.read_csv(f'data/L3/{asset_names[0].split('-')[-1]}/df_101_basdt_241217.csv')\n",
    "   df_101['VAR_NM'] = df_101['RIC'].map(var_dict_101)\n",
    "   df_101 = df_101[['TRADEDATE', 'RIC', 'VAR_NM', 'PI']]\n",
    "\n",
    "   # Grouping and restructuring the data\n",
    "   grouped_data = []\n",
    "   for (ric, var_nm), group in df_101.groupby([\"RIC\", \"VAR_NM\"]):\n",
    "      entries = group[[\"TRADEDATE\", \"PI\"]].to_dict(orient=\"records\")\n",
    "      grouped_data.append({\"RIC\": ric, \"VAR_NM\": var_nm, \"entries\": entries})\n",
    "\n",
    "   # Output JSON\n",
    "   table_101_data = json.dumps(grouped_data, indent=2)\n",
    "except:\n",
    "   table_101_data = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "   df_102 = pd.read_csv(f'data/L3/{asset_names[0].split('-')[-1]}/df_102_basdt_241217.csv')\n",
    "   df_102['VAR_NM'] = df_102['RIC'].map(var_dict_102)\n",
    "   df_102 = df_102[['TRADEDATE', 'RIC', 'VAR_NM', 'RY']]\n",
    "\n",
    "   # Grouping and restructuring the data\n",
    "   grouped_data = []\n",
    "   for (ric, var_nm), group in df_102.groupby([\"RIC\", \"VAR_NM\"]):\n",
    "      entries = group[[\"TRADEDATE\", \"RY\"]].to_dict(orient=\"records\")\n",
    "      grouped_data.append({\"RIC\": ric, \"VAR_NM\": var_nm, \"entries\": entries})\n",
    "\n",
    "   # Output JSON\n",
    "   table_102_data = json.dumps(grouped_data, indent=2)\n",
    "except:\n",
    "   table_102_data = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "   df_103 = pd.read_csv(f'data/L3/{asset_names[0].split('-')[-1]}/df_103_basdt_241217.csv')\n",
    "   df_103['VAR_NM'] = df_103['RIC'].map(var_dict_103)\n",
    "   df_103 = df_103[['TRADEDATE', 'RIC', 'VAR_NM', 'PS']]\n",
    "\n",
    "   # Grouping and restructuring the data\n",
    "   grouped_data = []\n",
    "   for (ric, var_nm), group in df_103.groupby([\"RIC\", \"VAR_NM\"]):\n",
    "      entries = group[[\"TRADEDATE\", \"PS\"]].to_dict(orient=\"records\")\n",
    "      grouped_data.append({\"RIC\": ric, \"VAR_NM\": var_nm, \"entries\": entries})\n",
    "\n",
    "   # Output JSON\n",
    "   table_103_data = json.dumps(grouped_data, indent=2)\n",
    "except:\n",
    "   table_103_data = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "   df_104 = pd.read_csv(f'data/L3/{asset_names[0].split('-')[-1]}/df_104_basdt_241217.csv')\n",
    "   df_104['VAR_NM'] = df_104['RIC'].map(var_dict_104)\n",
    "   df_104 = df_104[['TRADEDATE', 'RIC', 'VAR_NM', 'ER']]\n",
    "\n",
    "   # Grouping and restructuring the data\n",
    "   grouped_data = []\n",
    "   for (ric, var_nm), group in df_104.groupby([\"RIC\", \"VAR_NM\"]):\n",
    "      entries = group[[\"TRADEDATE\", \"ER\"]].to_dict(orient=\"records\")\n",
    "      grouped_data.append({\"RIC\": ric, \"VAR_NM\": var_nm, \"entries\": entries})\n",
    "\n",
    "   # Output JSON\n",
    "   table_104_data = json.dumps(grouped_data, indent=2)\n",
    "except:\n",
    "   table_104_data = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "   df_105 = pd.read_csv(f'data/L3/{asset_names[0].split('-')[-1]}/df_105_basdt_241217.csv')\n",
    "   df_105['VAR_NM'] = df_105['RIC'].map(var_dict_105)\n",
    "   df_105 = df_105[['TRADEDATE', 'RIC', 'VAR_NM', 'P']]\n",
    "\n",
    "   # Grouping and restructuring the data\n",
    "   grouped_data = []\n",
    "   for (ric, var_nm), group in df_105.groupby([\"RIC\", \"VAR_NM\"]):\n",
    "      entries = group[[\"TRADEDATE\", \"P\"]].to_dict(orient=\"records\")\n",
    "      grouped_data.append({\"RIC\": ric, \"VAR_NM\": var_nm, \"entries\": entries})\n",
    "\n",
    "   # Output JSON\n",
    "   table_105_data = json.dumps(grouped_data, indent=2)\n",
    "except:\n",
    "   table_105_data = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-4. 모델 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-5. 설명 타겟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. **Gradual Increase in Weight (November 20 to December 16, 2024):** The weight of the asset group \"AA-ETF_EQUITY-XLU\" shows a steady and gradual increase from 0.0059 on November 20 to 0.0101 on December 16. This change is relatively easy to explain as it could be attributed to a consistent positive performance or a strategic decision to increase exposure to this asset group over time.\n",
      "\n",
      "2. **Significant Jump in Weight (December 16 to December 17, 2024):** There is a notable and sudden increase in the weight from 0.0101 on December 16 to 0.0145 on December 17. This significant jump could be due to a major event or news affecting the asset group, such as a regulatory change, a merger, or a significant market movement that prompted a rapid adjustment in the portfolio.\n",
      "\n",
      "3. **Overall Trend and Strategic Implications:** The overall trend from November 20 to December 17 shows a consistent increase in the weight of the asset group, culminating in a sharp rise on December 17. This complex change might indicate a strategic shift in the portfolio's focus towards this asset group, possibly due to anticipated future performance, changes in market conditions, or a rebalancing strategy to align with new investment goals or risk assessments.\n"
     ]
    }
   ],
   "source": [
    "AI_model_result = df_infc.drop_duplicates(['BAS_DT', 'ASET_GRP'])[['BAS_DT', 'ASET_GRP', 'ASET_GRP_WGT']].reset_index(drop=True)\n",
    "\n",
    "# Grouping and restructuring the data\n",
    "grouped_data = []\n",
    "for aset_grp, group in AI_model_result.groupby(\"ASET_GRP\"):\n",
    "    entries = group[[\"BAS_DT\", \"ASET_GRP_WGT\"]].to_dict(orient=\"records\")\n",
    "    grouped_data.append({\"ASET_GRP\": aset_grp, \"entries\": entries})\n",
    "\n",
    "# Output JSON\n",
    "AI_model_result = json.dumps(grouped_data, indent=2)\n",
    "\n",
    "AI_model_result = llm.invoke(\n",
    "        [SystemMessage(content=\"Extract 3 most notable weight changes in the portfolio optimization results below. List them from relatively easy to explain to complex. There should be no overlap in contents.\")] + \n",
    "        [HumanMessage(content=AI_model_result)]\n",
    "        )\n",
    "AI_model_result = AI_model_result.content\n",
    "print(AI_model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-6. 설명력 스코어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Correlations: The variables with positive correlations include \"CME-LIVE CATTLE COMP. TRc1\" with a high influence score of 0.93, \"BMF-BOVESPA INDEX TRc1\" with a score of 0.91, and \"LIFFE-WHITE SUGAR TRc1\" with a score of 0.35. Other positively correlated variables with moderate influence scores are \"NYMEX - Brent Crude Oil LST Day TRC1\" at 0.25, \"Chicago Board of Trade (CBOT)-Corn Composite TRC1\" peaking at 0.19, and \"BRAZIL BOVESPA\" reaching 0.18. Additionally, \"Japanese Yen to United States Dollar (Refinitiv)\" and \"United States Dollar to Euro 1 Month Forward Points\" both show influence scores up to 0.19, while \"NYM-NY HARBOR ULSD TRc1\" and \"Refinitiv Brazil Government Benchmark Bid Yield 10 Years\" have lower scores around 0.13. \"NYM-PLATINUM TRc1\" also shows a positive trend with scores up to 0.20.\n",
      "\n",
      "Negative Correlations: The variables with negative correlations include \"CME-MINI S&P 500 INDEX TRc1\" with a score of 0.61, \"EUREX-DJ EURO STOXX 50 TRc1\" with a score of 0.62, and \"NYM-PALLADIUM TRc1\" with a score of 0.74. \"OSX-NIKKEI 225 INDEX TRc1\" shows a significant negative influence with a score of 0.54. \"Gold, USD FX Composite U United States Dollar Per Troy Ounce\" and \"London Metal Exchange (LME)-Copper Grade A Cash United States Dollar Per Metric Tonne\" have scores reaching 0.50 and 0.45, respectively. \"Korea Stock Exchange Composite (KOSPI)\" and \"Refinitiv Brazil Government Benchmark Bid Yield 3 Years\" show influence scores up to 0.24 and 0.19, respectively. \"FTSE 100\" and \"Standard and Poors / ASX All Ordinaries Gold Open\" have lower scores around 0.16, while \"United States Dollar to Euro 2 Month Forward Points\" shows a consistent negative trend with scores up to 0.22.\n",
      "\n",
      "Other Variables: The variable \"Refinitiv S Korea Government Benchmark Bid Yield 3 Years\" shows a single entry with a positive influence score of 0.12. This variable does not exhibit a consistent trend over time, making it less significant compared to others with more frequent entries and higher influence scores.\n"
     ]
    }
   ],
   "source": [
    "XAI_model_result = df_infc[['BAS_DT', 'VAR_NM', 'INFC_SCRE', 'INFC_DIR']].reset_index(drop=True)\n",
    "\n",
    "# Grouping and restructuring the data\n",
    "grouped_data = []\n",
    "for var_nm, group in XAI_model_result.groupby(\"VAR_NM\"):\n",
    "    entries = group[['BAS_DT', 'INFC_SCRE', 'INFC_DIR']].to_dict(orient=\"records\")\n",
    "    grouped_data.append({\"VAR_NM\": var_nm, \"entries\": entries})\n",
    "\n",
    "# Output JSON\n",
    "XAI_model_result = json.dumps(grouped_data, indent=2)\n",
    "\n",
    "XAI_model_result = llm.invoke(\n",
    "        [SystemMessage(content=f\"Interpret the temporal trend of daily influence score data (Shapley value) of explanatory variables for daily weight determination of {asset_names[0]} in the portfolio. List them in order of Meaning of Correlation (as you understand), Positive Correlations, Negative Correlations, and Other Variables, one paragraph each. Positive and negative scores indicate positive and negative correlations, respectively. Higher absolute value of influence score means higher influence. Preserve important details and include no preamble.\")] + \n",
    "        [HumanMessage(content=XAI_model_result)]\n",
    "        )\n",
    "XAI_model_result = XAI_model_result.content\n",
    "print(XAI_model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1. Analyst 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "from IPython.display import Image, display\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "class Analyst(BaseModel):\n",
    "    name: str = Field(description=\"Name of the analyst.\")\n",
    "    role: str = Field(description=\"Role of the analyst.\")\n",
    "    affiliation: str = Field(description=\"Primary affiliation of the analyst.\")\n",
    "    description: str = Field(description=\"Description of the analyst's focus, concerns, and motives.\")\n",
    "\n",
    "    @property\n",
    "    def persona(self) -> str:\n",
    "        return f\"Name: {self.name}\\nRole: {self.role}\\nAffiliation: {self.affiliation}\\nDescription: {self.description}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import List, Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "class ResearchGraphState(TypedDict):\n",
    "    human_analyst_feedback: str\n",
    "    analysts: List[Analyst]\n",
    "    sections: Annotated[list, operator.add]\n",
    "    # interpretations: Annotated[list, operator.add]\n",
    "    content: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_analysts(state: ResearchGraphState):\n",
    "    \"\"\" No-op node for creating analysts \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_feedback(state: ResearchGraphState):\n",
    "    \"\"\" No-op node that should be interrupted on \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. Interview 서브그래프 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Question 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "class InterviewState(MessagesState):\n",
    "    max_num_turns: int\n",
    "    analyst: Analyst\n",
    "    context: Annotated[list, operator.add]\n",
    "    interview: str\n",
    "    sections: list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_subquestions = 3\n",
    "max_num_turns = 3\n",
    "\n",
    "analysts = [Analyst(name='Emma Thompson', role='Equity Market Analyst', affiliation='Global Equities Research', description='Emma focuses on the dynamics of equity markets, particularly the impact of global indices such as the FTSE 100, KOSPI, and BOVESPA on portfolio optimization. She is concerned with how these indices reflect broader economic trends and investor sentiment, and how they interact with volatility indicators like the ASX All Ordinaries Gold Open.'),\n",
    " Analyst(name='Carlos Mendes', role='Fixed Income Strategist', affiliation='Latin America Bond Insights', description='Carlos specializes in government bond yields, with a particular focus on Brazilian and South Korean markets. He analyzes how changes in benchmark yields, such as the 10-year and 3-year Brazilian government bonds, influence investment strategies and risk assessments in portfolio optimization.'),\n",
    " Analyst(name='Sophia Lee', role='Commodities Analyst', affiliation='Global Commodities Watch', description='Sophia examines the role of commodities and futures in portfolio optimization, focusing on key indicators like Brent Crude Oil, Corn, and precious metals such as Palladium and Platinum. Her analysis includes understanding how these commodities influence market dynamics and investor behavior.'),\n",
    " Analyst(name=\"Liam O'Connor\", role='Currency Market Analyst', affiliation='International Forex Review', description='Liam provides insights into currency exchange rates, particularly the USD to Euro forward points and the JPY to USD exchange rate. He focuses on how these rates affect international trade and investment flows, without engaging in pair trading strategies.'),\n",
    " Analyst(name='Isabella Rossi', role='Market Index Specialist', affiliation='Metals and Indices Analysis', description=\"Isabella's expertise lies in market indices, with a focus on the London Metal Exchange's Copper Grade A and Gold USD FX Composite. She analyzes how these indices serve as economic indicators and their impact on portfolio diversification and risk management.\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_instructions = \"\"\"You are an analyst tasked with interviewing an expert. \n",
    "\n",
    "Your goal is to explain the AI model result of portfolio optimization from your professional perspective and data.\n",
    "\n",
    "It is extremely important to focus on gathering information on high-level themes such as market dynamics, fund flows, and potential risks.\n",
    "(Caution: Focus on a subset of explanatory variables. DO NOT focus on too many or too few explanatory variables.)\n",
    "\n",
    "Your target assets:\n",
    "{asset_names}.\n",
    "\n",
    "Your explanation target (AI model result):\n",
    "{AI_model_result}.\n",
    "\n",
    "Explanatory variables that AI model considered important (Note: Daily data exists for past days.):\n",
    "{var_dict}.\n",
    "\n",
    "Reference information to use when asking question (Explainable AI model result):\n",
    "{XAI_model_result}\n",
    "\n",
    "Your persona:\n",
    "{persona}.\n",
    "\n",
    "Your task:\n",
    "\n",
    "1. Start interview by introducing yourself.\n",
    "2. Come up with a challenging and complex first question for the first explanation target.\n",
    "3. Break this first question into very specific sub-questions. Make {num_subquestions} sub-questions.\n",
    "  (Caution: From the original question, make sub-questions that can be answered/inferred directly from your knowledge and the past daily data of one or more explanatory variables.\n",
    "   Select explanatory variables that are closely related to your persona. Sub-questions should not be too trivial or complex. Use exact name for explanatory variables.)\n",
    "4. Review the answer from the expert and state your overall understanding of previous sub-questions (`## Understanding` header).\n",
    "   Then, move on to the next explanation target and come up with a new challenging and complex question, saying \"Let's move on to the next explanation target!\".\n",
    "  (Note: There are total 3 explanation targets.)\n",
    "   Also, break the new question into sub-questions (`## Questions` header).\n",
    "  (Caution: From the original question, make sub-questions that can be answered/inferred directly from your knowledge and the past daily data of one or more explanatory variables.\n",
    "   Select explanatory variables that are closely related to your persona. Sub-questions should not be too trivial or complex. Use exact name for explanatory variables.)\n",
    "   Through iteration, boil down to interesting and specific insights.\n",
    "    - Interesting: Insights that people will find surprising or non-obvious.   \n",
    "    - Specific: Insights that avoid generalities and include specific figures.\n",
    "5. To complete the interview, use these criterion:\n",
    "    - You are very confident about being ready to explain the target result.\n",
    "    - You have gained enough interesting and specific insights. \n",
    "    - There are no more appropriate questions.\n",
    "   \n",
    "   Complete the interview like this:\n",
    "    - Say \"I'd like to finish my interview with the expert since I'm ready for impressive explanation!\".\n",
    "    - Briefly state the prepared explanation and how this explanation can be considered an achievement of your goal.\n",
    "\n",
    "Output format:\n",
    "\n",
    "1. Include no preamble.\n",
    "2. Use markdown formatting and follow this structure:\n",
    "\n",
    "   ## Understanding\n",
    "   <Overall understanding>\n",
    "   ## Questions\n",
    "   1. [Question] <Follow-up question>\n",
    "   2. [Sub-questions]\n",
    "      [Sub-question 1] <First sub-question>\n",
    "      [Sub-question 2] <Second sub-question>\n",
    "      [Sub-question 3] <Third sub-question>.\n",
    "\n",
    "Final review:\n",
    "\n",
    "1. Confirm that the task guidelines are all satisfied.\n",
    "2. Confirm that the output format guidelines are all satisfied.\"\"\"\n",
    "\n",
    "def generate_question(state: InterviewState):\n",
    "    \"\"\" Node to generate a question \"\"\"\n",
    "\n",
    "    # Get state\n",
    "    analyst = state[\"analyst\"]\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # LLM\n",
    "    system_message = question_instructions.format(\n",
    "        asset_names=asset_names,\n",
    "        AI_model_result=AI_model_result,\n",
    "        var_dict=var_dict,\n",
    "        XAI_model_result=XAI_model_result,\n",
    "        persona=analyst.persona,\n",
    "        num_subquestions=num_subquestions\n",
    "        )\n",
    "    question = llm.invoke(\n",
    "        [SystemMessage(content=system_message)] +\n",
    "        messages\n",
    "        )\n",
    "    \n",
    "    # Write messages to state\n",
    "    return {\"messages\": [question]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Context 추출 & Answer 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import get_buffer_string\n",
    "\n",
    "# Extract context\n",
    "extract_instructions = \"\"\"You will be given a conversation between an analyst and an expert.\n",
    "\n",
    "Your goal is to help the expert answer the analyst's questions by providing context.\n",
    "\n",
    "Your target assets:\n",
    "{asset_names}.\n",
    "\n",
    "Your task:\n",
    "\n",
    "1. Analyze the full conversation and pay particular attention to the analyst's last message, which contains sub-questions.\n",
    "2. Extract important context for each sub-question from table (`## Contexts` header).\n",
    "   Follow these guidelines:\n",
    "    - Handle ALL sub-questions posed by the analyst at last turn, one by one.\n",
    "    - When there is no context to extract, DO NOT make up any context and just return \"No context for this sub-question!\".\n",
    "3. Include the source (`### Source` header).\n",
    "\n",
    "Output format:\n",
    "\n",
    "1. Include no preamble.\n",
    "2. Use markdown formatting and follow this structure:\n",
    "\n",
    "   ## Contexts\n",
    "   1. [Question] <Follow-up question>\n",
    "   2. [Sub-questions]\n",
    "      [Sub-question 1] <First sub-question>: <Context for first sub-question>\n",
    "      [Sub-question 2] <Second sub-question>: <Context for second sub-question>\n",
    "      [Sub-question 3] <Third sub-question>: <Context for third sub-question>.\n",
    "   ### Source\n",
    "   <Source> or None (e.g., [Table 101]. DO NOT use this format: [1].).\n",
    "\n",
    "Final review:\n",
    "\n",
    "1. Confirm that the task guidelines are all satisfied.\n",
    "2. Confirm that the output format guidelines are all satisfied.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Equity and volatility indicator\n",
    "extract_101_instructions = extract_instructions + \"\"\"Available source:\n",
    "\n",
    "Table 101 has explanatory variables related to equity and volatility indicator.\n",
    "\n",
    "Explanatory variables:\n",
    "{var_dict}.\n",
    "\n",
    "Table data:\n",
    "{table_data}.\"\"\"\n",
    "\n",
    "# Government bond yield\n",
    "extract_102_instructions = extract_instructions + \"\"\"Available source:\n",
    "\n",
    "Table 102 has explanatory variables related to government bond yield.\n",
    "\n",
    "Explanatory variables:\n",
    "{var_dict}.\n",
    "\n",
    "Table data:\n",
    "{table_data}.\"\"\"\n",
    "\n",
    "# Commodities and Futures\n",
    "extract_103_instructions = extract_instructions + \"\"\"Available source:\n",
    "\n",
    "Table 103 has explanatory variables related to commodities and futures.\n",
    "\n",
    "Explanatory variables:\n",
    "{var_dict}.\n",
    "\n",
    "Table data:\n",
    "{table_data}.\"\"\"\n",
    "\n",
    "# Currency exchange rates\n",
    "extract_104_instructions = extract_instructions + \"\"\"Available source:\n",
    "\n",
    "Table 104 has explanatory variables related to currency exchange rates.\n",
    "\n",
    "Explanatory variables:\n",
    "{var_dict}.\n",
    "\n",
    "Table data:\n",
    "{table_data}.\"\"\"\n",
    "\n",
    "# Market index\n",
    "extract_105_instructions = extract_instructions + \"\"\"Available source:\n",
    "\n",
    "Table 105 has explanatory variables related to market index.\n",
    "\n",
    "Explanatory variables:\n",
    "{var_dict}.\n",
    "\n",
    "Table data:\n",
    "{table_data}.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DSC101TH\n",
    "def search_equity_and_volatility(state: InterviewState):\n",
    "    \"\"\" Extract context from table \"\"\"\n",
    "\n",
    "    # Get state\n",
    "    messages = state['messages']\n",
    "    \n",
    "    # LLM\n",
    "    system_message = extract_101_instructions.format(\n",
    "        asset_names=asset_names,\n",
    "        var_dict=var_dict_101,\n",
    "        table_data=table_101_data\n",
    "        )\n",
    "    # structured_llm = llm.with_structured_output(SearchQuery)\n",
    "    extract_result = llm.invoke(\n",
    "        [SystemMessage(content=system_message)] +\n",
    "        messages\n",
    "        )\n",
    "    \n",
    "    return {\"context\": [extract_result.content]}\n",
    "\n",
    "# DSC102TH\n",
    "def search_government_bond_yield(state: InterviewState):\n",
    "    \"\"\" Extract context from table \"\"\"\n",
    "\n",
    "    # Get state\n",
    "    messages = state['messages']\n",
    "    \n",
    "    # LLM\n",
    "    system_message = extract_102_instructions.format(\n",
    "        asset_names=asset_names,\n",
    "        var_dict=var_dict_102,\n",
    "        table_data=table_102_data\n",
    "        )\n",
    "    # structured_llm = llm.with_structured_output(SearchQuery)\n",
    "    extract_result = llm.invoke(\n",
    "        [SystemMessage(content=system_message)] +\n",
    "        messages\n",
    "        )\n",
    "    \n",
    "    return {\"context\": [extract_result.content]}\n",
    "\n",
    "# DSC103TH\n",
    "def search_commodities_and_futures(state: InterviewState):\n",
    "    \"\"\" Extract context from table \"\"\"\n",
    "\n",
    "    # Get state\n",
    "    messages = state['messages']\n",
    "    \n",
    "    # LLM\n",
    "    system_message = extract_103_instructions.format(\n",
    "        asset_names=asset_names,\n",
    "        var_dict=var_dict_103,\n",
    "        table_data=table_103_data\n",
    "        )\n",
    "    # structured_llm = llm.with_structured_output(SearchQuery)\n",
    "    extract_result = llm.invoke(\n",
    "        [SystemMessage(content=system_message)] +\n",
    "        messages\n",
    "        )\n",
    "    \n",
    "    return {\"context\": [extract_result.content]}\n",
    "\n",
    "# DSC104TH\n",
    "def search_currency_exchange_rates(state: InterviewState):\n",
    "    \"\"\" Extract context from table \"\"\"\n",
    "\n",
    "    # Get state\n",
    "    messages = state['messages']\n",
    "    \n",
    "    # LLM\n",
    "    system_message = extract_104_instructions.format(\n",
    "        asset_names=asset_names,\n",
    "        var_dict=var_dict_104,\n",
    "        table_data=table_104_data\n",
    "        )\n",
    "    # structured_llm = llm.with_structured_output(SearchQuery)\n",
    "    extract_result = llm.invoke(\n",
    "        [SystemMessage(content=system_message)] +\n",
    "        messages\n",
    "        )\n",
    "    \n",
    "    return {\"context\": [extract_result.content]}\n",
    "\n",
    "# DSC105TH\n",
    "def search_market_index(state: InterviewState):\n",
    "    \"\"\" Extract context from table \"\"\"\n",
    "\n",
    "    # Get state\n",
    "    messages = state['messages']\n",
    "    \n",
    "    # LLM\n",
    "    system_message = extract_105_instructions.format(\n",
    "        asset_names=asset_names,\n",
    "        var_dict=var_dict_105,\n",
    "        table_data=table_105_data\n",
    "        )\n",
    "    # structured_llm = llm.with_structured_output(SearchQuery)\n",
    "    extract_result = llm.invoke(\n",
    "        [SystemMessage(content=system_message)] +\n",
    "        messages\n",
    "        )\n",
    "    \n",
    "    return {\"context\": [extract_result.content]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_instructions = \"\"\"You are an expert being interviewed by an analyst.\n",
    "\n",
    "Your goal is to answer the analyst's questions based on the provided context.\n",
    "\n",
    "Your target assets:\n",
    "{asset_names}.\n",
    "\n",
    "Your explanation target (AI model result):\n",
    "{AI_model_result}.\n",
    "\n",
    "Analyst's persona:\n",
    "{persona}.\n",
    "\n",
    "Your task:\n",
    "\n",
    "1. Analyze the full conversation and pay particular attention to the analyst's last message, which contains sub-questions.\n",
    "2. Answer the questions (`## Answer` header).\n",
    "   Follow these guidelines:\n",
    "    - Answer all sub-questions posed by the analyst at last turn, one by one, using the provided context.\n",
    "     (Caution: DO NOT handle just single sub-quesiton.)\n",
    "    - Only use the provided context. When the provided context is insufficient, DO NOT make up any answer and just mention specifically what additional context you need.\n",
    "     (Caution: DO NOT leverage external or unknown contexts that are not provided.)\n",
    "    - Include source next to any relevant statements (e.g., for Table 102 use [Table 102].).\n",
    "    - Create a list of sources (`### Sources` header).\n",
    "    \n",
    "Output format:\n",
    "\n",
    "1. Include no preamble.\n",
    "2. Use markdown formatting and follow this structure:\n",
    "\n",
    "   ## Answer\n",
    "   [Sub-question 1] <First sub-question>: <Answer for first sub-question>\n",
    "   [Sub-question 2] <Second sub-question>: <Answer for second sub-question>\n",
    "   [Sub-question 3] <Third sub-question>: <Answer for third sub-question>\n",
    "   ### Sources\n",
    "   <Source 1>, <Source 2>, etc. (e.g., [Table 101], [Table 102]. DO NOT use this format: [1], [2].).\n",
    "\n",
    "Final review:\n",
    "\n",
    "1. Confirm that the task guidelines are all satisfied.\n",
    "2. Confirm that the output format guidelines are all satisfied.\n",
    "\n",
    "Provided context:\n",
    "{context}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(state: InterviewState):\n",
    "    \"\"\" Node to answer a question \"\"\"\n",
    "\n",
    "    # Get state\n",
    "    analyst = state[\"analyst\"]\n",
    "    context = state[\"context\"]\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    # LLM\n",
    "    system_message = answer_instructions.format(\n",
    "        asset_names=asset_names,\n",
    "        AI_model_result=AI_model_result,\n",
    "        persona=analyst.persona,\n",
    "        context=context\n",
    "        )\n",
    "    answer = llm.invoke(\n",
    "        [SystemMessage(content=system_message)] +\n",
    "        messages\n",
    "        )\n",
    "    \n",
    "    # Name the message as coming from the expert\n",
    "    answer.name = \"expert\"\n",
    "    \n",
    "    return {\"messages\": [answer]}\n",
    "\n",
    "def save_interview(state: InterviewState):\n",
    "    \"\"\" Save interviews \"\"\"\n",
    "\n",
    "    # Get state\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # Convert interview to a string\n",
    "    interview = get_buffer_string(messages)\n",
    "    \n",
    "    return {\"interview\": interview}\n",
    "\n",
    "def route_messages(state: InterviewState, \n",
    "                   name: str = \"expert\"):\n",
    "    \"\"\" Route between question and answer \"\"\"\n",
    "    \n",
    "    # Get state\n",
    "    messages = state[\"messages\"]\n",
    "    max_num_turns = state[\"max_num_turns\"]\n",
    "\n",
    "    # Check the number of expert answers \n",
    "    num_responses = len(\n",
    "        [m for m in messages if isinstance(m, AIMessage) and m.name == name]\n",
    "    )\n",
    "\n",
    "    # End if expert has answered more than the max turns\n",
    "    if num_responses >= max_num_turns:\n",
    "        return 'save_interview'\n",
    "\n",
    "    # This router is run after each question - answer pair \n",
    "    # Get the last question asked to check if it signals the end of discussion\n",
    "    last_question = messages[-2]\n",
    "    \n",
    "    if \"I'd like to finish my interview with expert since I'm ready for impressive explanation!\" in last_question.content:\n",
    "        return 'save_interview'\n",
    "    \n",
    "    return \"ask_question\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Section 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_writer_instructions = \"\"\"You are a technical writer specializing in the finance field.\n",
    "\n",
    "Your goal is to write a section based on the provided interview transcript.\n",
    "\n",
    "Your task:\n",
    "\n",
    "1. Review the information of interviewer:\n",
    "{description}\n",
    "2. Create a narrative by gathering and understanding valid sub-question and answer pairs from the interview transcript.\n",
    "3. Write Body part (`## Section` header).\n",
    "   Follow these guidelines:\n",
    "    - DO NOT mention any interviewer and interviewee names.\n",
    "    - Aim for approximately 500 words maximum and 3 paragraphs with sub-title (`### Sub-title` header). Keep the flow of the interview as close as possible.\n",
    "     (Caution: DO NOT over-abbreviate original meaningful insights and figures.)\n",
    "    - Aim to preserve the provided important figures and sources.\n",
    "     (Caution: When making a new sentence by combining sentences with explicit source, include the new source next to this made-up sentence. It can be multiple sources like [Table 101], [Table 102].).\n",
    "4. Write Sources part (`### Sources` header).\n",
    "   Follow these guidelines:\n",
    "    - Create a list of sources.\n",
    "    - Be sure that there is no redundant sources.\n",
    "\n",
    "Output format:\n",
    "\n",
    "1. Include no preamble.\n",
    "2. Use markdown formatting and follow this structure:\n",
    "    ## Section\n",
    "    ### <Sub-title 1>\n",
    "    ### <Sub-title 2>\n",
    "    ### <Sub-title 3>\n",
    "    ### Sources \n",
    "    <Source 1>, <Source 2>, etc. (e.g., [Table 101], [Table 102]. DO NOT use this format: [1], [2].).\n",
    "\n",
    "Final review:\n",
    "\n",
    "1. Confirm that the task guidelines are all satisfied.\n",
    "2. Confirm that the output format guidelines are all satisfied.\"\"\"\n",
    "\n",
    "def write_section(state: InterviewState):\n",
    "    \"\"\" Node to answer a question \"\"\"\n",
    "\n",
    "    # Get state\n",
    "    interview = state[\"interview\"]\n",
    "    analyst = state[\"analyst\"]\n",
    "    \n",
    "    # LLM (use context)\n",
    "    system_message = section_writer_instructions.format(description=analyst.description)\n",
    "    section = llm.invoke(\n",
    "        [SystemMessage(content=system_message)] +\n",
    "        [HumanMessage(content=f\"Use this interview transcript to write your section: {interview}\")]\n",
    "        ) \n",
    "    \n",
    "    # Append it to state\n",
    "    return {\"sections\": [section.content]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add nodes and edges \n",
    "interview_builder = StateGraph(InterviewState)\n",
    "interview_builder.add_node(\"ask_question\", generate_question)\n",
    "interview_builder.add_node(\"search_equity_and_volatility\", search_equity_and_volatility)\n",
    "interview_builder.add_node(\"search_government_bond_yield\", search_government_bond_yield)\n",
    "interview_builder.add_node(\"search_commodities_and_futures\", search_commodities_and_futures)\n",
    "interview_builder.add_node(\"search_currency_exchange_rates\", search_currency_exchange_rates)\n",
    "interview_builder.add_node(\"search_market_index\", search_market_index)\n",
    "interview_builder.add_node(\"answer_question\", generate_answer)\n",
    "interview_builder.add_node(\"save_interview\", save_interview)\n",
    "interview_builder.add_node(\"write_section\", write_section)\n",
    "\n",
    "# Flow\n",
    "interview_builder.add_edge(START, \"ask_question\")\n",
    "interview_builder.add_edge(\"ask_question\", \"search_equity_and_volatility\")\n",
    "interview_builder.add_edge(\"ask_question\", \"search_government_bond_yield\")\n",
    "interview_builder.add_edge(\"ask_question\", \"search_commodities_and_futures\")\n",
    "interview_builder.add_edge(\"ask_question\", \"search_currency_exchange_rates\")\n",
    "interview_builder.add_edge(\"ask_question\", \"search_market_index\")\n",
    "interview_builder.add_edge(\"search_equity_and_volatility\", \"answer_question\")\n",
    "interview_builder.add_edge(\"search_government_bond_yield\", \"answer_question\")\n",
    "interview_builder.add_edge(\"search_commodities_and_futures\", \"answer_question\")\n",
    "interview_builder.add_edge(\"search_currency_exchange_rates\", \"answer_question\")\n",
    "interview_builder.add_edge(\"search_market_index\", \"answer_question\")\n",
    "interview_builder.add_conditional_edges(\"answer_question\", route_messages, ['ask_question', 'save_interview'])\n",
    "interview_builder.add_edge(\"save_interview\", \"write_section\")\n",
    "interview_builder.add_edge(\"write_section\", END)\n",
    "\n",
    "# Interview \n",
    "memory = MemorySaver()\n",
    "interview_graph = interview_builder.compile(checkpointer=memory).with_config(run_name=\"Conduct Interviews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-3. Interview 수행 (Parallelization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.constants import Send\n",
    "\n",
    "# Conditional edge\n",
    "def initiate_all_interviews(state: ResearchGraphState):\n",
    "    \"\"\" This is the \"map\" step where we run each interview sub-graph using Send API \"\"\"    \n",
    "\n",
    "    # Check if human feedback\n",
    "    human_analyst_feedback = state.get('human_analyst_feedback')\n",
    "    if human_analyst_feedback:\n",
    "        # Return to create_analysts\n",
    "        return \"create_analysts\"\n",
    "\n",
    "    # Otherwise kick off interviews in parallel via Send() API\n",
    "    else:\n",
    "        messages = [HumanMessage(content=\"So you said you were explaining the AI model result of portfolio optimization?\")]\n",
    "        return [Send(\"conduct_interview\",\n",
    "                     {\"analyst\": analyst,\n",
    "                      \"max_num_turns\": max_num_turns,\n",
    "                      \"messages\": messages}) for analyst in state[\"analysts\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-4. Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-5. Report 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_writer_instructions = \"\"\"You are a technical writer specializing in the finance field.\n",
    "\n",
    "Your goal is to write a technical report that explains the AI model result of portfolio optimization by integrating the provided sections.\n",
    "\n",
    "It is extremely important to focus on on high-level themes such as market dynamics, fund flows, and potential risks.\n",
    "\n",
    "Your target assets:\n",
    "{asset_names}.\n",
    "\n",
    "Your explanation target (AI model result):\n",
    "{AI_model_result}.\n",
    "\n",
    "Your task:\n",
    "\n",
    "1. Analyze all the sections provided by several analysts.\n",
    "2. Think carefully about insights from the provided sections.\n",
    "3. Consolidate the insights to come up with impressive explanation.\n",
    "4. Create a holistic narrative that reflects your persona and connects the insights together.\n",
    "   This holistic narrative focuses on high-level themes such as market dynamics, fund flows, and potential risks.\n",
    "5. Write Body part (`## Analysis` header).\n",
    "   Follow these guidelines:\n",
    "    - Assume general readers with extensive knowledge about investment.\n",
    "    - Tone and manner must be technical and clear.\n",
    "    - Begin by briefly summarizing 3 explanation targets (`### Target` header).\n",
    "    - Emphasize the novelty of your insights.\n",
    "    - DO NOT mention any imaginary names.\n",
    "    - Aim for approximately 750 words maximum and 3 paragraphs with sub-title (`### Sub-title` header). Each paragraph should correspond to individual explanation target.\n",
    "     (Caution: Avoid vague phrases that are not specific and have no impact. DO NOT over-abbreviate original meaningful insights and figures.)\n",
    "    - Aim to preserve the provided important figures and sources.\n",
    "     (Caution: When making a new sentence by combining sentences with explicit sources, include the new source next to this made-up sentence. It can be multiple sources like [Table 101], [Table 102].).\n",
    "6. Write Recommendation part.\n",
    "   Follow these guidelines:\n",
    "    - Assume general readers with extensive knowledge about investment.\n",
    "    - Tone and manner must be technical and clear.\n",
    "    - DO NOT mention any imaginary names.\n",
    "    - Aim for approximately 250 words maximum and 1 paragraph.\n",
    "     (Caution: Avoid vague phrases that are not specific and have no impact.)\n",
    "    - Use <Score>/5 format for `### Score` header (5/5: Highly recommended, 1/5: Highly not recommended).\n",
    "    - Explain the reason for the score decision (`### Reason` header).\n",
    "7. Write Sources part (`### Sources` header).\n",
    "   Follow these guidelines:\n",
    "    - Create a list of sources.\n",
    "    - Be sure that there is no redundant sources.\n",
    "8. Come up with an engaging and focused title (`# Title` header).\n",
    "  (Caution: Avoid vague phrases that are not specific and have no impact.)\n",
    "9. Provide the original English version AND Korean version report.\n",
    "\n",
    "Output format:\n",
    "\n",
    "1. Include no preamble.\n",
    "2. For English version, use markdown formatting and follow this structure:\n",
    "    # <Title>\n",
    "    ## Market Analysis Result\n",
    "    ### Target\n",
    "    ### <Sub-title 1>\n",
    "    ### <Sub-title 2>\n",
    "    ### <Sub-title 3>\n",
    "    ## Recommendation\n",
    "    ### Score\n",
    "    ### Reason\n",
    "    ### Sources (e.g., [Table 101], [Table 102]. DO NOT use this format: [1], [2].).\n",
    "3. 한국어 버전에 마크다운 포맷을 적용하고 다음 구조를 따르세요:\n",
    "    # <제목>\n",
    "    ## 시장 분석 결과\n",
    "    ### 타겟\n",
    "    ### <소제목 1>\n",
    "    ### <소제목 2>\n",
    "    ### <소제목 3>\n",
    "    ## 추천\n",
    "    ### 점수\n",
    "    ### 근거\n",
    "    ### 출처.\n",
    "    \n",
    "Final review:\n",
    "\n",
    "1. Confirm that the task guidelines are all satisfied.\n",
    "2. Confirm that the output format guidelines are all satisfied.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_report(state: ResearchGraphState):\n",
    "    # Full set of sections\n",
    "    sections = state[\"sections\"]\n",
    "    \n",
    "    # Concat all sections together\n",
    "    formatted_str_sections = \"\\n\\n\".join([f\"{section}\" for section in sections])\n",
    "    \n",
    "    # LLM\n",
    "    system_message = report_writer_instructions.format(\n",
    "        asset_names=asset_names,\n",
    "        AI_model_result=AI_model_result)    \n",
    "    report = llm.invoke(\n",
    "        [SystemMessage(content=system_message)] + \n",
    "        [HumanMessage(content=f\"Write a report based on the provided sections. Here are the sections: {formatted_str_sections}\")])\n",
    "    \n",
    "    return {\"content\": report.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add nodes and edges \n",
    "builder = StateGraph(ResearchGraphState)\n",
    "builder.add_node(\"create_analysts\", create_analysts)\n",
    "builder.add_node(\"human_feedback\", human_feedback)\n",
    "builder.add_node(\"conduct_interview\", interview_builder.compile())\n",
    "# builder.add_node(\"interpret_risk_seeking\", interpret_risk_seeking)\n",
    "# builder.add_node(\"interpret_stability_seeking\", interpret_stability_seeking)\n",
    "# builder.add_node(\"interpret_balanced\", interpret_balanced)\n",
    "builder.add_node(\"write_report\", write_report)\n",
    "\n",
    "# Logic\n",
    "builder.add_edge(START, \"create_analysts\")\n",
    "builder.add_edge(\"create_analysts\", \"human_feedback\")\n",
    "builder.add_conditional_edges(\"human_feedback\", initiate_all_interviews, [\"create_analysts\", \"conduct_interview\"])\n",
    "# builder.add_edge(\"conduct_interview\", \"interpret_risk_seeking\")\n",
    "# builder.add_edge(\"conduct_interview\", \"interpret_stability_seeking\")\n",
    "# builder.add_edge(\"conduct_interview\", \"interpret_balanced\")\n",
    "# builder.add_edge(\"interpret_risk_seeking\", \"write_report\")\n",
    "# builder.add_edge(\"interpret_stability_seeking\", \"write_report\")\n",
    "# builder.add_edge(\"interpret_balanced\", \"write_report\")\n",
    "builder.add_edge(\"conduct_interview\", \"write_report\")\n",
    "builder.add_edge(\"write_report\", END)\n",
    "\n",
    "# Compile\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(interrupt_before=['human_feedback'], checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-6. 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Emma Thompson\n",
      "Affiliation: Global Equities Research\n",
      "Role: Equity Market Analyst\n",
      "Description: Emma focuses on the dynamics of equity markets, particularly the impact of global indices such as the FTSE 100, KOSPI, and BOVESPA on portfolio optimization. She is concerned with how these indices reflect broader economic trends and investor sentiment, and how they interact with volatility indicators like the ASX All Ordinaries Gold Open.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Name: Carlos Mendes\n",
      "Affiliation: Latin America Bond Insights\n",
      "Role: Fixed Income Strategist\n",
      "Description: Carlos specializes in government bond yields, with a particular focus on Brazilian and South Korean markets. He analyzes how changes in benchmark yields, such as the 10-year and 3-year Brazilian government bonds, influence investment strategies and risk assessments in portfolio optimization.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Name: Sophia Lee\n",
      "Affiliation: Global Commodities Watch\n",
      "Role: Commodities Analyst\n",
      "Description: Sophia examines the role of commodities and futures in portfolio optimization, focusing on key indicators like Brent Crude Oil, Corn, and precious metals such as Palladium and Platinum. Her analysis includes understanding how these commodities influence market dynamics and investor behavior.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Name: Liam O'Connor\n",
      "Affiliation: International Forex Review\n",
      "Role: Currency Market Analyst\n",
      "Description: Liam provides insights into currency exchange rates, particularly the USD to Euro forward points and the JPY to USD exchange rate. He focuses on how these rates affect international trade and investment flows, without engaging in pair trading strategies.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Name: Isabella Rossi\n",
      "Affiliation: Metals and Indices Analysis\n",
      "Role: Market Index Specialist\n",
      "Description: Isabella's expertise lies in market indices, with a focus on the London Metal Exchange's Copper Grade A and Gold USD FX Composite. She analyzes how these indices serve as economic indicators and their impact on portfolio diversification and risk management.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Run the graph until the first interruption\n",
    "for event in graph.stream({\"analysts\": analysts}, # {\"max_analysts\": max_analysts}\n",
    "                          thread, \n",
    "                          stream_mode=\"values\"):\n",
    "    \n",
    "    analysts = event.get('analysts', '')\n",
    "    if analysts:\n",
    "        for analyst in analysts:\n",
    "            print(f\"Name: {analyst.name}\")\n",
    "            print(f\"Affiliation: {analyst.affiliation}\")\n",
    "            print(f\"Role: {analyst.role}\")\n",
    "            print(f\"Description: {analyst.description}\")\n",
    "            print(\"-\" * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1efbe9a2-5570-6a84-8002-9fa82dd7e063'}}"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm we are happy\n",
    "further_feedack = None\n",
    "graph.update_state(\n",
    "    thread,\n",
    "    {\"human_analyst_feedback\": further_feedack},\n",
    "    as_node=\"human_feedback\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Node--\n",
      "conduct_interview\n",
      "--Node--\n",
      "conduct_interview\n",
      "--Node--\n",
      "conduct_interview\n",
      "--Node--\n",
      "conduct_interview\n",
      "--Node--\n",
      "conduct_interview\n",
      "--Node--\n",
      "write_report\n"
     ]
    }
   ],
   "source": [
    "# Continue\n",
    "for event in graph.stream(None, thread, stream_mode=\"updates\"):\n",
    "    print(\"--Node--\")\n",
    "    node_name = next(iter(event.keys()))\n",
    "    print(node_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Portfolio Optimization Analysis: AA-ETF_EQUITY-XLU\n",
       "\n",
       "## Market Analysis Result\n",
       "\n",
       "### Target\n",
       "\n",
       "The AI model's analysis of the asset group \"AA-ETF_EQUITY-XLU\" reveals three distinct phases in its weight adjustment within the portfolio from November 20 to December 17, 2024. Initially, there is a gradual increase in weight, followed by a significant jump, and finally, an overall trend that suggests strategic implications. These changes are influenced by various market dynamics, fund flows, and potential risks, which are crucial for understanding the portfolio's optimization strategy.\n",
       "\n",
       "### Gradual Increase in Weight\n",
       "\n",
       "The gradual increase in the weight of \"AA-ETF_EQUITY-XLU\" from November 20 to December 16, 2024, can be attributed to several key market dynamics. The \"BRAZIL BOVESPA\" index, with an influence score of 0.18, and the \"CME-LIVE CATTLE COMP. TRc1,\" with a high influence score of 0.93, played significant roles in this period. These indices' positive performances likely created a favorable environment for the asset group, encouraging its increased weight in the portfolio. Additionally, the \"Refinitiv Brazil Government Benchmark Bid Yield 10 Years\" contributed positively with an influence score of 0.13, reflecting a calculated approach to portfolio optimization. These elements collectively supported the strategic decision to increase exposure to this asset group, indicating a response to broader market confidence and economic conditions in Brazil [Table 101], [Table 102].\n",
       "\n",
       "### Significant Jump in Weight\n",
       "\n",
       "The significant jump in the weight of \"AA-ETF_EQUITY-XLU\" from December 16 to December 17, 2024, is linked to negative correlations with certain market variables. The \"CME-MINI S&P 500 INDEX TRc1\" had a negative influence score of 0.61, suggesting a downturn in its performance. Similarly, the \"EUREX-DJ EURO STOXX 50 TRc1\" and \"NYM-PALLADIUM TRc1\" showed negative influence scores of 0.62 and 0.74, respectively. These negative correlations likely prompted a rapid adjustment in the portfolio, leading to the sudden increase in weight as a strategic response to mitigate potential risks and capitalize on emerging opportunities. This shift underscores the dynamic interplay between market events and investor sentiment, highlighting the importance of agility in portfolio management [Table 103].\n",
       "\n",
       "### Strategic Implications\n",
       "\n",
       "The overall trend and sharp rise in the weight of \"AA-ETF_EQUITY-XLU\" by December 17, 2024, carry significant strategic implications for portfolio management. The performance of the \"Korea Stock Exchange Composite (KOSPI)\" and its influence score would have been critical in assessing broader market sentiment and economic trends. Additionally, the trend in \"Gold, USD FX Composite U United States Dollar Per Troy Ounce\" and its influence score provide insights into investor behavior and risk appetite. Furthermore, changes in the \"London Metal Exchange (LME)-Copper Grade A Cash United States Dollar Per Metric Tonne\" reflect shifts in industrial demand and global economic conditions. These strategic considerations highlight the importance of dynamic portfolio adjustments in response to evolving market conditions and underscore the need for continuous monitoring and analysis of key economic indicators [Table 104], [Table 105].\n",
       "\n",
       "## Recommendation\n",
       "\n",
       "### Score\n",
       "\n",
       "4/5\n",
       "\n",
       "### Reason\n",
       "\n",
       "The strategic increase in the weight of \"AA-ETF_EQUITY-XLU\" within the portfolio from November 20 to December 17, 2024, is highly recommended due to its alignment with positive market dynamics and strategic risk management. The gradual increase reflects a calculated response to favorable economic conditions, particularly in Brazil, and the significant jump indicates a proactive approach to mitigating risks associated with negative market correlations. The overall trend suggests a strategic shift towards this asset group, supported by key economic indicators and market sentiment. However, investors should remain vigilant and continuously monitor market conditions and economic indicators to ensure the portfolio's alignment with evolving market dynamics and investment goals.\n",
       "\n",
       "### Sources\n",
       "\n",
       "[Table 101], [Table 102], [Table 103], [Table 104], [Table 105].\n",
       "\n",
       "# 포트폴리오 최적화 분석: AA-ETF_EQUITY-XLU\n",
       "\n",
       "## 시장 분석 결과\n",
       "\n",
       "### 타겟\n",
       "\n",
       "AI 모델의 \"AA-ETF_EQUITY-XLU\" 자산 그룹 분석은 2024년 11월 20일부터 12월 17일까지 포트폴리오 내에서 세 가지 뚜렷한 단계의 가중치 조정을 보여줍니다. 초기에는 점진적인 가중치 증가가 있으며, 그 후에는 상당한 점프가 있고, 마지막으로 전략적 함의를 시사하는 전반적인 추세가 있습니다. 이러한 변화는 다양한 시장 역학, 자금 흐름 및 잠재적 위험에 의해 영향을 받으며, 포트폴리오 최적화 전략을 이해하는 데 중요합니다.\n",
       "\n",
       "### 점진적인 가중치 증가\n",
       "\n",
       "2024년 11월 20일부터 12월 16일까지 \"AA-ETF_EQUITY-XLU\"의 가중치가 점진적으로 증가한 것은 여러 주요 시장 역학에 기인할 수 있습니다. \"BRAZIL BOVESPA\" 지수는 0.18의 영향 점수를 가지고 있으며, \"CME-LIVE CATTLE COMP. TRc1\"은 0.93의 높은 영향 점수를 가지고 있어 이 기간 동안 중요한 역할을 했습니다. 이러한 지수의 긍정적인 성과는 이 자산 그룹에 유리한 환경을 조성하여 포트폴리오 내에서 가중치 증가를 장려했을 가능성이 큽니다. 또한, \"Refinitiv Brazil Government Benchmark Bid Yield 10 Years\"는 0.13의 영향 점수로 긍정적인 기여를 하여 포트폴리오 최적화에 대한 계산된 접근 방식을 반영합니다. 이러한 요소들은 집합적으로 이 자산 그룹에 대한 노출을 증가시키려는 전략적 결정을 지원하며, 브라질의 광범위한 시장 신뢰와 경제 조건에 대한 대응을 나타냅니다 [Table 101], [Table 102].\n",
       "\n",
       "### 가중치의 급격한 점프\n",
       "\n",
       "2024년 12월 16일부터 12월 17일까지 \"AA-ETF_EQUITY-XLU\"의 가중치가 급격히 증가한 것은 특정 시장 변수와의 부정적인 상관관계와 관련이 있습니다. \"CME-MINI S&P 500 INDEX TRc1\"은 0.61의 부정적인 영향 점수를 가지고 있어 성과가 하락했음을 시사합니다. 마찬가지로, \"EUREX-DJ EURO STOXX 50 TRc1\"과 \"NYM-PALLADIUM TRc1\"은 각각 0.62와 0.74의 부정적인 영향 점수를 보여줍니다. 이러한 부정적인 상관관계는 포트폴리오의 급속한 조정을 촉발하여 잠재적 위험을 완화하고 새로운 기회를 활용하기 위한 전략적 대응으로 가중치의 급격한 증가를 초래했을 가능성이 큽니다. 이 변화는 시장 이벤트와 투자자 심리 간의 역동적인 상호작용을 강조하며, 포트폴리오 관리에서의 민첩성의 중요성을 강조합니다 [Table 103].\n",
       "\n",
       "### 전략적 함의\n",
       "\n",
       "2024년 12월 17일까지 \"AA-ETF_EQUITY-XLU\"의 가중치의 전반적인 추세와 급격한 증가는 포트폴리오 관리에 중요한 전략적 함의를 가집니다. 이 기간 동안 \"Korea Stock Exchange Composite (KOSPI)\"의 성과와 그 영향 점수는 광범위한 시장 심리와 경제 동향을 평가하는 데 중요한 역할을 했을 것입니다. 또한, \"Gold, USD FX Composite U United States Dollar Per Troy Ounce\"의 추세와 그 영향 점수는 투자자 행동과 위험 선호도를 이해하는 데 도움을 줍니다. 더 나아가, \"London Metal Exchange (LME)-Copper Grade A Cash United States Dollar Per Metric Tonne\"의 변화는 산업 수요와 글로벌 경제 조건의 변화를 반영합니다. 이러한 전략적 고려 사항은 변화하는 시장 조건에 대한 동적 포트폴리오 조정의 중요성을 강조하며, 주요 경제 지표의 지속적인 모니터링과 분석의 필요성을 강조합니다 [Table 104], [Table 105].\n",
       "\n",
       "## 추천\n",
       "\n",
       "### 점수\n",
       "\n",
       "4/5\n",
       "\n",
       "### 근거\n",
       "\n",
       "2024년 11월 20일부터 12월 17일까지 포트폴리오 내에서 \"AA-ETF_EQUITY-XLU\"의 가중치 증가 전략은 긍정적인 시장 역학 및 전략적 위험 관리와의 정렬로 인해 강력히 추천됩니다. 점진적인 증가는 특히 브라질의 유리한 경제 조건에 대한 계산된 대응을 반영하며, 상당한 점프는 부정적인 시장 상관관계와 관련된 위험을 완화하기 위한 적극적인 접근 방식을 나타냅니다. 전반적인 추세는 주요 경제 지표와 시장 심리에 의해 뒷받침되는 이 자산 그룹으로의 전략적 전환을 시사합니다. 그러나 투자자들은 포트폴리오가 변화하는 시장 역학 및 투자 목표와의 정렬을 보장하기 위해 시장 조건과 경제 지표를 지속적으로 모니터링해야 합니다.\n",
       "\n",
       "### 출처\n",
       "\n",
       "[Table 101], [Table 102], [Table 103], [Table 104], [Table 105]."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "final_state = graph.get_state(thread)\n",
    "report = final_state.values.get('content')\n",
    "Markdown(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Portfolio Optimization Analysis: AA-ETF_EQUITY-XLU\\n\\n## Market Analysis Result\\n\\n### Target\\n\\nThe AI model\\'s analysis of the asset group \"AA-ETF_EQUITY-XLU\" reveals three distinct phases in its weight adjustment within the portfolio from November 20 to December 17, 2024. Initially, there is a gradual increase in weight, followed by a significant jump, and finally, an overall trend that suggests strategic implications. These changes are influenced by various market dynamics, fund flows, and potential risks, which are crucial for understanding the portfolio\\'s optimization strategy.\\n\\n### Gradual Increase in Weight\\n\\nThe gradual increase in the weight of \"AA-ETF_EQUITY-XLU\" from November 20 to December 16, 2024, can be attributed to several key market dynamics. The \"BRAZIL BOVESPA\" index, with an influence score of 0.18, and the \"CME-LIVE CATTLE COMP. TRc1,\" with a high influence score of 0.93, played significant roles in this period. These indices\\' positive performances likely created a favorable environment for the asset group, encouraging its increased weight in the portfolio. Additionally, the \"Refinitiv Brazil Government Benchmark Bid Yield 10 Years\" contributed positively with an influence score of 0.13, reflecting a calculated approach to portfolio optimization. These elements collectively supported the strategic decision to increase exposure to this asset group, indicating a response to broader market confidence and economic conditions in Brazil [Table 101], [Table 102].\\n\\n### Significant Jump in Weight\\n\\nThe significant jump in the weight of \"AA-ETF_EQUITY-XLU\" from December 16 to December 17, 2024, is linked to negative correlations with certain market variables. The \"CME-MINI S&P 500 INDEX TRc1\" had a negative influence score of 0.61, suggesting a downturn in its performance. Similarly, the \"EUREX-DJ EURO STOXX 50 TRc1\" and \"NYM-PALLADIUM TRc1\" showed negative influence scores of 0.62 and 0.74, respectively. These negative correlations likely prompted a rapid adjustment in the portfolio, leading to the sudden increase in weight as a strategic response to mitigate potential risks and capitalize on emerging opportunities. This shift underscores the dynamic interplay between market events and investor sentiment, highlighting the importance of agility in portfolio management [Table 103].\\n\\n### Strategic Implications\\n\\nThe overall trend and sharp rise in the weight of \"AA-ETF_EQUITY-XLU\" by December 17, 2024, carry significant strategic implications for portfolio management. The performance of the \"Korea Stock Exchange Composite (KOSPI)\" and its influence score would have been critical in assessing broader market sentiment and economic trends. Additionally, the trend in \"Gold, USD FX Composite U United States Dollar Per Troy Ounce\" and its influence score provide insights into investor behavior and risk appetite. Furthermore, changes in the \"London Metal Exchange (LME)-Copper Grade A Cash United States Dollar Per Metric Tonne\" reflect shifts in industrial demand and global economic conditions. These strategic considerations highlight the importance of dynamic portfolio adjustments in response to evolving market conditions and underscore the need for continuous monitoring and analysis of key economic indicators [Table 104], [Table 105].\\n\\n## Recommendation\\n\\n### Score\\n\\n4/5\\n\\n### Reason\\n\\nThe strategic increase in the weight of \"AA-ETF_EQUITY-XLU\" within the portfolio from November 20 to December 17, 2024, is highly recommended due to its alignment with positive market dynamics and strategic risk management. The gradual increase reflects a calculated response to favorable economic conditions, particularly in Brazil, and the significant jump indicates a proactive approach to mitigating risks associated with negative market correlations. The overall trend suggests a strategic shift towards this asset group, supported by key economic indicators and market sentiment. However, investors should remain vigilant and continuously monitor market conditions and economic indicators to ensure the portfolio\\'s alignment with evolving market dynamics and investment goals.\\n\\n### Sources\\n\\n[Table 101], [Table 102], [Table 103], [Table 104], [Table 105].\\n\\n# 포트폴리오 최적화 분석: AA-ETF_EQUITY-XLU\\n\\n## 시장 분석 결과\\n\\n### 타겟\\n\\nAI 모델의 \"AA-ETF_EQUITY-XLU\" 자산 그룹 분석은 2024년 11월 20일부터 12월 17일까지 포트폴리오 내에서 세 가지 뚜렷한 단계의 가중치 조정을 보여줍니다. 초기에는 점진적인 가중치 증가가 있으며, 그 후에는 상당한 점프가 있고, 마지막으로 전략적 함의를 시사하는 전반적인 추세가 있습니다. 이러한 변화는 다양한 시장 역학, 자금 흐름 및 잠재적 위험에 의해 영향을 받으며, 포트폴리오 최적화 전략을 이해하는 데 중요합니다.\\n\\n### 점진적인 가중치 증가\\n\\n2024년 11월 20일부터 12월 16일까지 \"AA-ETF_EQUITY-XLU\"의 가중치가 점진적으로 증가한 것은 여러 주요 시장 역학에 기인할 수 있습니다. \"BRAZIL BOVESPA\" 지수는 0.18의 영향 점수를 가지고 있으며, \"CME-LIVE CATTLE COMP. TRc1\"은 0.93의 높은 영향 점수를 가지고 있어 이 기간 동안 중요한 역할을 했습니다. 이러한 지수의 긍정적인 성과는 이 자산 그룹에 유리한 환경을 조성하여 포트폴리오 내에서 가중치 증가를 장려했을 가능성이 큽니다. 또한, \"Refinitiv Brazil Government Benchmark Bid Yield 10 Years\"는 0.13의 영향 점수로 긍정적인 기여를 하여 포트폴리오 최적화에 대한 계산된 접근 방식을 반영합니다. 이러한 요소들은 집합적으로 이 자산 그룹에 대한 노출을 증가시키려는 전략적 결정을 지원하며, 브라질의 광범위한 시장 신뢰와 경제 조건에 대한 대응을 나타냅니다 [Table 101], [Table 102].\\n\\n### 가중치의 급격한 점프\\n\\n2024년 12월 16일부터 12월 17일까지 \"AA-ETF_EQUITY-XLU\"의 가중치가 급격히 증가한 것은 특정 시장 변수와의 부정적인 상관관계와 관련이 있습니다. \"CME-MINI S&P 500 INDEX TRc1\"은 0.61의 부정적인 영향 점수를 가지고 있어 성과가 하락했음을 시사합니다. 마찬가지로, \"EUREX-DJ EURO STOXX 50 TRc1\"과 \"NYM-PALLADIUM TRc1\"은 각각 0.62와 0.74의 부정적인 영향 점수를 보여줍니다. 이러한 부정적인 상관관계는 포트폴리오의 급속한 조정을 촉발하여 잠재적 위험을 완화하고 새로운 기회를 활용하기 위한 전략적 대응으로 가중치의 급격한 증가를 초래했을 가능성이 큽니다. 이 변화는 시장 이벤트와 투자자 심리 간의 역동적인 상호작용을 강조하며, 포트폴리오 관리에서의 민첩성의 중요성을 강조합니다 [Table 103].\\n\\n### 전략적 함의\\n\\n2024년 12월 17일까지 \"AA-ETF_EQUITY-XLU\"의 가중치의 전반적인 추세와 급격한 증가는 포트폴리오 관리에 중요한 전략적 함의를 가집니다. 이 기간 동안 \"Korea Stock Exchange Composite (KOSPI)\"의 성과와 그 영향 점수는 광범위한 시장 심리와 경제 동향을 평가하는 데 중요한 역할을 했을 것입니다. 또한, \"Gold, USD FX Composite U United States Dollar Per Troy Ounce\"의 추세와 그 영향 점수는 투자자 행동과 위험 선호도를 이해하는 데 도움을 줍니다. 더 나아가, \"London Metal Exchange (LME)-Copper Grade A Cash United States Dollar Per Metric Tonne\"의 변화는 산업 수요와 글로벌 경제 조건의 변화를 반영합니다. 이러한 전략적 고려 사항은 변화하는 시장 조건에 대한 동적 포트폴리오 조정의 중요성을 강조하며, 주요 경제 지표의 지속적인 모니터링과 분석의 필요성을 강조합니다 [Table 104], [Table 105].\\n\\n## 추천\\n\\n### 점수\\n\\n4/5\\n\\n### 근거\\n\\n2024년 11월 20일부터 12월 17일까지 포트폴리오 내에서 \"AA-ETF_EQUITY-XLU\"의 가중치 증가 전략은 긍정적인 시장 역학 및 전략적 위험 관리와의 정렬로 인해 강력히 추천됩니다. 점진적인 증가는 특히 브라질의 유리한 경제 조건에 대한 계산된 대응을 반영하며, 상당한 점프는 부정적인 시장 상관관계와 관련된 위험을 완화하기 위한 적극적인 접근 방식을 나타냅니다. 전반적인 추세는 주요 경제 지표와 시장 심리에 의해 뒷받침되는 이 자산 그룹으로의 전략적 전환을 시사합니다. 그러나 투자자들은 포트폴리오가 변화하는 시장 역학 및 투자 목표와의 정렬을 보장하기 위해 시장 조건과 경제 지표를 지속적으로 모니터링해야 합니다.\\n\\n### 출처\\n\\n[Table 101], [Table 102], [Table 103], [Table 104], [Table 105].'"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mi_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
