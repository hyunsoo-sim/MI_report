{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 환경 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. 환경 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. 기본 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "from textwrap import dedent\n",
    "from pprint import pprint\n",
    "\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import uuid\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option('display.max_rows', 30)\n",
    "pd.set_option('display.max_columns', 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "타겟 자산명 (직접 작성)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asset_names = ['AA-ETF_EQUITY-SPY']\n",
    "# asset_names = ['AA-ETF_EQUITY-XLK', 'AA-ETF_EQUITY-XLE', 'AA-ETF_EQUITY-XLF', 'AA-ETF_EQUITY-XLV', 'AA-ETF_EQUITY-XLP', 'AA-ETF_EQUITY-XLI', 'AA-ETF_EQUITY-XLU']\n",
    "# asset_names = ['AA-ETF_EQUITY-EWY', 'AA-ETF_EQUITY-VWO', 'AA-ETF_EQUITY-EWC', 'AA-ETF_EQUITY-EFA', 'AA-ETF_EQUITY-EWJ', 'AA-ETF_EQUITY-EPP']\n",
    "asset_names = ['AA-ETF_EQUITY-ACWV', 'AA-ETF_EQUITY-SUSL', 'AA-ETF_EQUITY-SCHD', 'AA-ETF_EQUITY-VYMI', 'AA-ETF_EQUITY-VTV'] # ['AA-ETF_EQUITY-ACWV.K', 'AA-ETF_EQUITY-SUSL.O', 'AA-ETF_EQUITY-SCHD.K', 'AA-ETF_EQUITY-VYMI.O', 'AA-ETF_EQUITY-VTV']\n",
    "\n",
    "# cluster_name = 'SPY'\n",
    "# cluster_name = 'US-SECTOR'\n",
    "# cluster_name = 'exUS'\n",
    "cluster_name = 'US-STYLE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. 자산배분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BAS_DT</th>\n",
       "      <th>ASET_GRP</th>\n",
       "      <th>ASET_GRP_WGT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-10-23</td>\n",
       "      <td>AA-ETF_BOND-BND</td>\n",
       "      <td>0.0151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-10-23</td>\n",
       "      <td>AA-ETF_BOND-BNDX</td>\n",
       "      <td>0.0210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-10-23</td>\n",
       "      <td>AA-ETF_EQUITY-ACWV</td>\n",
       "      <td>0.0397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-10-23</td>\n",
       "      <td>AA-ETF_EQUITY-EFA</td>\n",
       "      <td>0.0132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-10-23</td>\n",
       "      <td>AA-ETF_EQUITY-EPP</td>\n",
       "      <td>0.0132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>2024-11-20</td>\n",
       "      <td>AA-ETF_EQUITY-XLK</td>\n",
       "      <td>0.2156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>2024-11-20</td>\n",
       "      <td>AA-ETF_EQUITY-XLP</td>\n",
       "      <td>0.0025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>2024-11-20</td>\n",
       "      <td>AA-ETF_EQUITY-XLU</td>\n",
       "      <td>0.0059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>2024-11-20</td>\n",
       "      <td>AA-ETF_EQUITY-XLV</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>2024-11-20</td>\n",
       "      <td>AA-ETF_SUB-CASH</td>\n",
       "      <td>0.2867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>483 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         BAS_DT            ASET_GRP  ASET_GRP_WGT\n",
       "0    2024-10-23     AA-ETF_BOND-BND        0.0151\n",
       "1    2024-10-23    AA-ETF_BOND-BNDX        0.0210\n",
       "2    2024-10-23  AA-ETF_EQUITY-ACWV        0.0397\n",
       "3    2024-10-23   AA-ETF_EQUITY-EFA        0.0132\n",
       "4    2024-10-23   AA-ETF_EQUITY-EPP        0.0132\n",
       "..          ...                 ...           ...\n",
       "478  2024-11-20   AA-ETF_EQUITY-XLK        0.2156\n",
       "479  2024-11-20   AA-ETF_EQUITY-XLP        0.0025\n",
       "480  2024-11-20   AA-ETF_EQUITY-XLU        0.0059\n",
       "481  2024-11-20   AA-ETF_EQUITY-XLV        0.0002\n",
       "482  2024-11-20     AA-ETF_SUB-CASH        0.2867\n",
       "\n",
       "[483 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_alloc = pd.read_csv('data/alloc_basdt_241120.csv')\n",
    "df_alloc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. 설명력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BAS_DT</th>\n",
       "      <th>ASET_GRP</th>\n",
       "      <th>ASET_GRP_WGT</th>\n",
       "      <th>RIC</th>\n",
       "      <th>VAR_NM</th>\n",
       "      <th>INFC_DIR</th>\n",
       "      <th>TABLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-10-23</td>\n",
       "      <td>AA-ETF_EQUITY-ACWV</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>.GVZ</td>\n",
       "      <td>CBOE GOLD VOLATILITY INDEX</td>\n",
       "      <td>-</td>\n",
       "      <td>DSC101TH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-10-23</td>\n",
       "      <td>AA-ETF_EQUITY-ACWV</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>.OVX</td>\n",
       "      <td>CBOE CRUDE OIL VOLATILITY INDEX</td>\n",
       "      <td>+</td>\n",
       "      <td>DSC101TH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-10-23</td>\n",
       "      <td>AA-ETF_EQUITY-ACWV</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>.VXEWZ</td>\n",
       "      <td>CBOE BRAZIL ETF VOLATILITY INDEX</td>\n",
       "      <td>-</td>\n",
       "      <td>DSC101TH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-10-23</td>\n",
       "      <td>AA-ETF_EQUITY-ACWV</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>CNY=</td>\n",
       "      <td>Chinese Yuan to United States Dollar (Refinitiv)</td>\n",
       "      <td>-</td>\n",
       "      <td>DSC104TH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-10-23</td>\n",
       "      <td>AA-ETF_EQUITY-ACWV</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>.JNIV</td>\n",
       "      <td>NIKKEI STOCK AVERAGE VOLATILITY INDEX</td>\n",
       "      <td>-</td>\n",
       "      <td>DSC101TH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>2024-11-20</td>\n",
       "      <td>AA-ETF_EQUITY-VYMI</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>CNY=</td>\n",
       "      <td>Chinese Yuan to United States Dollar (Refinitiv)</td>\n",
       "      <td>-</td>\n",
       "      <td>DSC104TH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>2024-11-20</td>\n",
       "      <td>AA-ETF_EQUITY-VYMI</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>.N225</td>\n",
       "      <td>NIKKEI 225 STOCK AVERAGE</td>\n",
       "      <td>+</td>\n",
       "      <td>DSC101TH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>2024-11-20</td>\n",
       "      <td>AA-ETF_EQUITY-VYMI</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>US3YT=RRPS</td>\n",
       "      <td>Refinitiv United States Government Benchmark B...</td>\n",
       "      <td>+</td>\n",
       "      <td>DSC102TH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>2024-11-20</td>\n",
       "      <td>AA-ETF_EQUITY-VYMI</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>.INX</td>\n",
       "      <td>CME-Standard and Poors 500 Index Composite CS02</td>\n",
       "      <td>+</td>\n",
       "      <td>DSC101TH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>2024-11-20</td>\n",
       "      <td>AA-ETF_EQUITY-VYMI</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>Sc1</td>\n",
       "      <td>Chicago Board of Trade (CBOT)-Soybeans Composi...</td>\n",
       "      <td>+</td>\n",
       "      <td>DSC103TH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>981 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         BAS_DT            ASET_GRP  ASET_GRP_WGT         RIC  \\\n",
       "0    2024-10-23  AA-ETF_EQUITY-ACWV        0.0397        .GVZ   \n",
       "1    2024-10-23  AA-ETF_EQUITY-ACWV        0.0397        .OVX   \n",
       "2    2024-10-23  AA-ETF_EQUITY-ACWV        0.0397      .VXEWZ   \n",
       "3    2024-10-23  AA-ETF_EQUITY-ACWV        0.0397        CNY=   \n",
       "4    2024-10-23  AA-ETF_EQUITY-ACWV        0.0397       .JNIV   \n",
       "..          ...                 ...           ...         ...   \n",
       "976  2024-11-20  AA-ETF_EQUITY-VYMI        0.0044        CNY=   \n",
       "977  2024-11-20  AA-ETF_EQUITY-VYMI        0.0044       .N225   \n",
       "978  2024-11-20  AA-ETF_EQUITY-VYMI        0.0044  US3YT=RRPS   \n",
       "979  2024-11-20  AA-ETF_EQUITY-VYMI        0.0044        .INX   \n",
       "980  2024-11-20  AA-ETF_EQUITY-VYMI        0.0044         Sc1   \n",
       "\n",
       "                                                VAR_NM INFC_DIR     TABLE  \n",
       "0                           CBOE GOLD VOLATILITY INDEX        -  DSC101TH  \n",
       "1                      CBOE CRUDE OIL VOLATILITY INDEX        +  DSC101TH  \n",
       "2                     CBOE BRAZIL ETF VOLATILITY INDEX        -  DSC101TH  \n",
       "3     Chinese Yuan to United States Dollar (Refinitiv)        -  DSC104TH  \n",
       "4                NIKKEI STOCK AVERAGE VOLATILITY INDEX        -  DSC101TH  \n",
       "..                                                 ...      ...       ...  \n",
       "976   Chinese Yuan to United States Dollar (Refinitiv)        -  DSC104TH  \n",
       "977                           NIKKEI 225 STOCK AVERAGE        +  DSC101TH  \n",
       "978  Refinitiv United States Government Benchmark B...        +  DSC102TH  \n",
       "979    CME-Standard and Poors 500 Index Composite CS02        +  DSC101TH  \n",
       "980  Chicago Board of Trade (CBOT)-Soybeans Composi...        +  DSC103TH  \n",
       "\n",
       "[981 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 전처리\n",
    "df_infc = pd.read_csv('data/infc_basdt_241120.csv')\n",
    "df_infc['ASET_GRP'] = df_infc['ASET_LEVEL'].str[3:]\n",
    "df_infc['ASET_LEVEL'] = df_infc['ASET_LEVEL'].str[:2]\n",
    "df_infc = df_infc[df_infc['ASET_GRP'].isin(asset_names)] # RIC 중복 존재 (기간 통합, L1-L3)\n",
    "\n",
    "df_infc = df_infc.merge(df_alloc, on=['BAS_DT', 'ASET_GRP'], how='inner')\n",
    "df_infc = df_infc[['BAS_DT', 'ASET_GRP', 'ASET_GRP_WGT', 'RIC', 'VAR_NM', 'INFC_DIR']]\n",
    "df_infc = df_infc.reset_index(drop=True)\n",
    "\n",
    "# 테이블명 추가\n",
    "df_var_map = pd.read_csv('data/var_table_mapping.csv')\n",
    "df_var_map = df_var_map[['RIC', 'TABLE']]\n",
    "df_var_map = df_var_map.drop_duplicates('RIC') # RIC 중복 제거 (필드만 다른 경우 존재)\n",
    "df_infc = df_infc.merge(df_var_map, on='RIC', how='inner')\n",
    "\n",
    "df_infc = df_infc.reset_index(drop=True)\n",
    "df_infc # 최종"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3. 기초 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 RIC (데이터 존재하는 것들만)\n",
    "RIC_101 = ['.AORD', '.BVSP', '.CSI300', '.FTSE', '.GDAXI', '.GVZ', '.INX', '.JNIV', '.KS11', '.KSVKOSPI', '.MOVE', '.N225', '.OVX', '.SKEWX', '.STOXX50E', '.V1XI', '.V2TX', '.VHSI', '.VIX', '.VXEWZ']\n",
    "RIC_102 = ['CN10YT=RR', 'CN3YT=RR', 'DE3YT=RR', 'KR3YT=RR', 'US10YT=RRPS', 'US3YT=RRPS']\n",
    "RIC_103 = ['Cc1', 'FCc1', 'GCc1', 'HGc1', 'HOc1', 'JNIc1', 'KCc1', 'LCOc1', 'LHc1', 'PLc1', 'Sc1']\n",
    "RIC_104 = ['BRL=', 'CNY=', 'EUR2M=', 'EUR=', 'GBP=', 'HKD=', 'JPY2M=', 'JPY=', 'KRW1M=', 'KRW2M=', 'KRW=']\n",
    "RIC_105 = ['MCU0', 'XAU=']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 변수 (데이터 존재하는 것들만)\n",
    "var_101 = [df_infc[df_infc['RIC'] == RIC_101[i]]['VAR_NM'].iloc[0] for i in range(len(RIC_101))]\n",
    "var_102 = [df_infc[df_infc['RIC'] == RIC_102[i]]['VAR_NM'].iloc[0] for i in range(len(RIC_102))]\n",
    "var_103 = [df_infc[df_infc['RIC'] == RIC_103[i]]['VAR_NM'].iloc[0] for i in range(len(RIC_103))]\n",
    "var_104 = [df_infc[df_infc['RIC'] == RIC_104[i]]['VAR_NM'].iloc[0] for i in range(len(RIC_104))]\n",
    "var_105 = [df_infc[df_infc['RIC'] == RIC_105[i]]['VAR_NM'].iloc[0] for i in range(len(RIC_105))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Equity and Volatility Indicators': ['Standard and Poors / ASX All Ordinaries Gold Open',\n",
       "  'BRAZIL BOVESPA',\n",
       "  'SHANGHAI SHENZHEN CSI 300',\n",
       "  'FTSE 100',\n",
       "  'DAX PERFORMANCE (XETRA)',\n",
       "  'CBOE GOLD VOLATILITY INDEX',\n",
       "  'CME-Standard and Poors 500 Index Composite CS02',\n",
       "  'NIKKEI STOCK AVERAGE VOLATILITY INDEX',\n",
       "  '[volume] Korea Stock Exchange Composite (KOSPI)',\n",
       "  'VKOSPI VOLATILITY INDEX',\n",
       "  'ML MOVE 1M BOND VOLATILITY INDEX',\n",
       "  'NIKKEI 225 STOCK AVERAGE',\n",
       "  'CBOE CRUDE OIL VOLATILITY INDEX',\n",
       "  'CBOE SKEW INDEX',\n",
       "  '[volume] EURO STOXX 50',\n",
       "  'VDAX-NEW VOLATILITY INDEX',\n",
       "  'VSTOXX VOLATILITY INDEX',\n",
       "  'HSI VOLATILITY INDEX',\n",
       "  'CBOE SPX VOLATILITY VIX (NEW)',\n",
       "  'CBOE BRAZIL ETF VOLATILITY INDEX'],\n",
       " 'Government Bond Yields': ['Refinitiv China Government Benchmark Bid Yield 10 Years',\n",
       "  'Refinitiv China Government Benchmark Bid Yield 3 Years',\n",
       "  'Refinitiv Germany Government Benchmark Bid Yield 3 Years',\n",
       "  'Refinitiv S Korea Government Benchmark Bid Yield 3 Years',\n",
       "  'Refinitiv United States Government Benchmark Bid Yield 10 Years',\n",
       "  'Refinitiv United States Government Benchmark Bid Yield 3 Years'],\n",
       " 'Commodities and Futures': ['Chicago Board of Trade (CBOT)-Corn Composite TRC1',\n",
       "  'CME-Feeder Cattle Composite TRC1',\n",
       "  'CMX-Gold 100 Ounce TRC1',\n",
       "  'CMX-HIGH GRADE COPPER TRc1',\n",
       "  'NYM-NY HARBOR ULSD TRc1',\n",
       "  'OSX-NIKKEI 225 INDEX TRc1',\n",
       "  \"CSCE-COFFEE 'C' TRc1\",\n",
       "  'Itercontinental Exchange (ICE) Brent Crude Oil TRC1',\n",
       "  'CME-LEAN HOGS COMP. TRc1',\n",
       "  'NYM-PLATINUM TRc1',\n",
       "  'Chicago Board of Trade (CBOT)-Soybeans Composite TRC1'],\n",
       " 'Currency Exchange Rates': ['Brazilian Real to United States Dollar (Refinitiv)',\n",
       "  'Chinese Yuan to United States Dollar (Refinitiv)',\n",
       "  'United States Dollar to Euro 2 Month Forward Points',\n",
       "  'United States Dollar to Euro (Refinitiv)',\n",
       "  'United States Dollar to United Kingdom Pound (Refinitiv)',\n",
       "  'Hong Kong Dollar to United States Dollar (Refinitiv)',\n",
       "  'Japanese Yen to United States Dollar 2 Month Forward Points',\n",
       "  'Japanese Yen to United States Dollar (Refinitiv)',\n",
       "  'South Korean Won to United States Dollar 1 Month Forward Points',\n",
       "  'South Korean Won to United States Dollar 2 Month Forward Points',\n",
       "  'South Korean Won to United States Dollar (Refinitiv)'],\n",
       " 'Market Index': ['London Metal Exchange (LME)-Copper Grade A Cash United States Dollar Per Metric Tonne',\n",
       "  'Gold, USD FX Composite U United States Dollar Per Troy Ounce']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_dict = {\n",
    "    'Equity and Volatility Indicators': var_101,\n",
    "    'Government Bond Yields': var_102,\n",
    "    'Commodities and Futures': var_103,\n",
    "    'Currency Exchange Rates': var_104,\n",
    "    'Market Index': var_105\n",
    "    }\n",
    "var_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_dict_101 = dict(zip(RIC_101, var_101))\n",
    "var_dict_102 = dict(zip(RIC_102, var_102))\n",
    "var_dict_103 = dict(zip(RIC_103, var_103))\n",
    "var_dict_104 = dict(zip(RIC_104, var_104))\n",
    "var_dict_105 = dict(zip(RIC_105, var_105))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "   df_101 = pd.read_csv(f'data/{cluster_name}/df_101_basdt_241120.csv')\n",
    "   df_101['VAR_NM'] = df_101['RIC'].map(var_dict_101)\n",
    "   df_101 = df_101[['TRADEDATE', 'RIC', 'VAR_NM', 'PI']]\n",
    "\n",
    "   # Grouping and restructuring the data\n",
    "   grouped_data = []\n",
    "   for (ric, var_nm), group in df_101.groupby([\"RIC\", \"VAR_NM\"]):\n",
    "      entries = group[[\"TRADEDATE\", \"PI\"]].to_dict(orient=\"records\")\n",
    "      grouped_data.append({\"RIC\": ric, \"VAR_NM\": var_nm, \"entries\": entries})\n",
    "\n",
    "   # Output JSON\n",
    "   table_101_data = json.dumps(grouped_data, indent=2)\n",
    "except:\n",
    "   table_101_data = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "   df_102 = pd.read_csv(f'data/{cluster_name}/df_102_basdt_241120.csv')\n",
    "   df_102['VAR_NM'] = df_102['RIC'].map(var_dict_102)\n",
    "   df_102 = df_102[['TRADEDATE', 'RIC', 'VAR_NM', 'RY']]\n",
    "\n",
    "   # Grouping and restructuring the data\n",
    "   grouped_data = []\n",
    "   for (ric, var_nm), group in df_102.groupby([\"RIC\", \"VAR_NM\"]):\n",
    "      entries = group[[\"TRADEDATE\", \"RY\"]].to_dict(orient=\"records\")\n",
    "      grouped_data.append({\"RIC\": ric, \"VAR_NM\": var_nm, \"entries\": entries})\n",
    "\n",
    "   # Output JSON\n",
    "   table_102_data = json.dumps(grouped_data, indent=2)\n",
    "except:\n",
    "   table_102_data = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "   df_103 = pd.read_csv(f'data/{cluster_name}/df_103_basdt_241120.csv')\n",
    "   df_103['VAR_NM'] = df_103['RIC'].map(var_dict_103)\n",
    "   df_103 = df_103[['TRADEDATE', 'RIC', 'VAR_NM', 'PS']]\n",
    "\n",
    "   # Grouping and restructuring the data\n",
    "   grouped_data = []\n",
    "   for (ric, var_nm), group in df_103.groupby([\"RIC\", \"VAR_NM\"]):\n",
    "      entries = group[[\"TRADEDATE\", \"PS\"]].to_dict(orient=\"records\")\n",
    "      grouped_data.append({\"RIC\": ric, \"VAR_NM\": var_nm, \"entries\": entries})\n",
    "\n",
    "   # Output JSON\n",
    "   table_103_data = json.dumps(grouped_data, indent=2)\n",
    "except:\n",
    "   table_103_data = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "   df_104 = pd.read_csv(f'data/{cluster_name}/df_104_basdt_241120.csv')\n",
    "   df_104['VAR_NM'] = df_104['RIC'].map(var_dict_104)\n",
    "   df_104 = df_104[['TRADEDATE', 'RIC', 'VAR_NM', 'ER']]\n",
    "\n",
    "   # Grouping and restructuring the data\n",
    "   grouped_data = []\n",
    "   for (ric, var_nm), group in df_104.groupby([\"RIC\", \"VAR_NM\"]):\n",
    "      entries = group[[\"TRADEDATE\", \"ER\"]].to_dict(orient=\"records\")\n",
    "      grouped_data.append({\"RIC\": ric, \"VAR_NM\": var_nm, \"entries\": entries})\n",
    "\n",
    "   # Output JSON\n",
    "   table_104_data = json.dumps(grouped_data, indent=2)\n",
    "except:\n",
    "   table_104_data = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "   df_105 = pd.read_csv(f'data/{cluster_name}/df_105_basdt_241120.csv')\n",
    "   df_105['VAR_NM'] = df_105['RIC'].map(var_dict_105)\n",
    "   df_105 = df_105[['TRADEDATE', 'RIC', 'VAR_NM', 'P']]\n",
    "\n",
    "   # Grouping and restructuring the data\n",
    "   grouped_data = []\n",
    "   for (ric, var_nm), group in df_105.groupby([\"RIC\", \"VAR_NM\"]):\n",
    "      entries = group[[\"TRADEDATE\", \"P\"]].to_dict(orient=\"records\")\n",
    "      grouped_data.append({\"RIC\": ric, \"VAR_NM\": var_nm, \"entries\": entries})\n",
    "\n",
    "   # Output JSON\n",
    "   table_105_data = json.dumps(grouped_data, indent=2)\n",
    "except:\n",
    "   table_105_data = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-4. 모델 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-5. 설명 타겟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI_model_result = df_infc.drop_duplicates(['BAS_DT', 'ASET_GRP'])[['BAS_DT', 'ASET_GRP', 'ASET_GRP_WGT']].reset_index(drop=True)\n",
    "\n",
    "# Grouping and restructuring the data\n",
    "grouped_data = []\n",
    "for aset_grp, group in AI_model_result.groupby(\"ASET_GRP\"):\n",
    "    entries = group[[\"BAS_DT\", \"ASET_GRP_WGT\"]].to_dict(orient=\"records\")\n",
    "    grouped_data.append({\"ASET_GRP\": aset_grp, \"entries\": entries})\n",
    "\n",
    "# Output JSON\n",
    "AI_model_result = json.dumps(grouped_data, indent=2)\n",
    "\n",
    "AI_model_result = llm.invoke(\n",
    "        [SystemMessage(content=\"Extract 3 things that stand out in the portfolio optimization results below. List them in order of importance. There should be no overlap.\")] + \n",
    "        [HumanMessage(content=AI_model_result)]\n",
    "        )\n",
    "AI_model_result = AI_model_result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1. Analyst 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "from IPython.display import Image, display\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "class Analyst(BaseModel):\n",
    "    name: str = Field(description=\"Name of the analyst.\")\n",
    "    role: str = Field(description=\"Role of the analyst.\")\n",
    "    affiliation: str = Field(description=\"Primary affiliation of the analyst.\")\n",
    "    description: str = Field(description=\"Description of the analyst's focus, concerns, and motives.\")\n",
    "\n",
    "    @property\n",
    "    def persona(self) -> str:\n",
    "        return f\"Name: {self.name}\\nRole: {self.role}\\nAffiliation: {self.affiliation}\\nDescription: {self.description}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import List, Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "class ResearchGraphState(TypedDict):\n",
    "    human_analyst_feedback: str\n",
    "    analysts: List[Analyst]\n",
    "    sections: Annotated[list, operator.add]\n",
    "    interpretations: Annotated[list, operator.add]\n",
    "    content: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_analysts(state: ResearchGraphState):\n",
    "    \"\"\" No-op node for creating analysts \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_feedback(state: ResearchGraphState):\n",
    "    \"\"\" No-op node that should be interrupted on \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. Interview 서브그래프 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Question 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "class InterviewState(MessagesState):\n",
    "    max_num_turns: int\n",
    "    analyst: Analyst\n",
    "    context: Annotated[list, operator.add]\n",
    "    interview: str\n",
    "    sections: list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_subquestions = 3\n",
    "max_num_turns = 3\n",
    "\n",
    "analysts = [Analyst(name='Emma Thompson', role='Global Market Strategist', affiliation='International Financial Advisory Group', description='Emma focuses on global market dynamics, analyzing how equity and volatility indicators interact with government bond yields to influence portfolio optimization. She is particularly interested in how shifts in major indices like the DAX and FTSE 100, combined with bond yield movements, can signal broader economic trends and impact asset allocation strategies.'),\n",
    " Analyst(name='Liam Chen', role='Commodities Analyst', affiliation='Global Commodities Research Institute', description='Liam specializes in the commodities and futures markets, examining how fluctuations in key commodities like gold, copper, and crude oil affect portfolio performance. He explores the interplay between commodity prices and equity markets, assessing how these relationships can inform risk management and diversification strategies.'),\n",
    " Analyst(name='Sophia Martinez', role='Fixed Income Specialist', affiliation='Bond Market Insights', description=\"Sophia's expertise lies in government bond yields and their implications for portfolio optimization. She analyzes how changes in yields across different countries, such as the US, China, and Germany, influence investment decisions and risk assessments. Her focus is on understanding the macroeconomic factors driving yield movements and their impact on equity markets.\"),\n",
    " Analyst(name='Noah Patel', role='Currency Market Analyst', affiliation='Forex and Macro Trends', description='Noah examines the influence of currency exchange rates on global investment strategies, focusing on how currency fluctuations can affect international portfolio returns. He provides insights into how exchange rate movements, particularly involving the USD, Euro, and emerging market currencies, can impact asset performance and investor sentiment.'),\n",
    " Analyst(name='Ava Johnson', role='Volatility and Risk Analyst', affiliation='Risk Management Solutions', description='Ava is dedicated to understanding market volatility and its implications for portfolio risk management. She analyzes volatility indices, such as the VIX and VDAX, to assess market sentiment and potential risks. Her work involves developing strategies to mitigate volatility-related risks and enhance portfolio resilience in uncertain market conditions.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_instructions = \"\"\"You are an analyst tasked with interviewing an expert. \n",
    "\n",
    "Your goal is to explain the AI model result of portfolio optimization from your professional perspective and data.\n",
    "\n",
    "It is extremely important to focus on gathering information on high-level themes such as market dynamics, fund flows, and potential risks.\n",
    "(Caution: Focus on a subset of explanatory variables. DO NOT focus on too many or too few explanatory variables.)\n",
    "\n",
    "Your target assets:\n",
    "{asset_names}.\n",
    "\n",
    "Your explanation target (AI model result):\n",
    "{AI_model_result}.\n",
    "\n",
    "Explanatory variables that AI model considered important (Note: Daily data exists for past 3 months.):\n",
    "{var_dict}.\n",
    "\n",
    "Your persona:\n",
    "{persona}.\n",
    "\n",
    "Your task:\n",
    "\n",
    "1. Start interview by introducing yourself.\n",
    "2. Come up with a challenging and complex first question for the first explanation target.\n",
    "3. Break this first question into very specific sub-questions. Make {num_subquestions} sub-questions.\n",
    "  (Caution: From the original question, make sub-questions that can be answered directly from the past daily explanatory variable data. Use exact name for explanatory variables.)\n",
    "4. Review the answer from the expert and state your overall understanding of previous sub-questions (`## Understanding` header).\n",
    "   Then, move on to the next explanation target and make new question, saying \"Let's move on to the next explanation target!\".\n",
    "  (Note: There are total 3 explanation targets.)\n",
    "   Also, break the new question into sub-questions (`## Questions` header).\n",
    "  (Caution: From the original question, make sub-questions that can be answered directly from the past daily explanatory variable data. Use exact name for explanatory variables.)\n",
    "   Through iteration, boil down to interesting and specific insights.\n",
    "    - Interesting: Insights that people will find surprising or non-obvious.   \n",
    "    - Specific: Insights that avoid generalities and include specific figures.\n",
    "5. To complete the interview, use these criterion:\n",
    "    - You are very confident about being ready to explain the target result.\n",
    "    - You have gained enough interesting and specific insights. \n",
    "    - There are no more appropriate questions.\n",
    "   \n",
    "   Complete the interview like this:\n",
    "    - Say \"I'd like to finish my interview with the expert since I'm ready for impressive explanation!\".\n",
    "    - Briefly state the prepared explanation and how this explanation can be considered an achievement of your goal.\n",
    "\n",
    "Output format:\n",
    "\n",
    "1. Include no preamble.\n",
    "2. Use markdown formatting and follow this structure:\n",
    "\n",
    "   ## Understanding\n",
    "   <Overall understanding>\n",
    "   ## Questions\n",
    "   1. [Question] <Follow-up question>\n",
    "   2. [Sub-questions]\n",
    "      [Sub-question 1] <First sub-question>\n",
    "      [Sub-question 2] <Second sub-question>\n",
    "      [Sub-question 3] <Third sub-question>.\n",
    "\n",
    "Final review:\n",
    "\n",
    "1. Confirm that the task guidelines are all satisfied.\n",
    "2. Confirm that the output format guidelines are all satisfied.\"\"\"\n",
    "\n",
    "def generate_question(state: InterviewState):\n",
    "    \"\"\" Node to generate a question \"\"\"\n",
    "\n",
    "    # Get state\n",
    "    analyst = state[\"analyst\"]\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # LLM\n",
    "    system_message = question_instructions.format(\n",
    "        asset_names=asset_names,\n",
    "        AI_model_result=AI_model_result,\n",
    "        var_dict=var_dict,\n",
    "        persona=analyst.persona,\n",
    "        num_subquestions=num_subquestions\n",
    "        )\n",
    "    question = llm.invoke(\n",
    "        [SystemMessage(content=system_message)] +\n",
    "        messages\n",
    "        )\n",
    "    \n",
    "    # Write messages to state\n",
    "    return {\"messages\": [question]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Context 추출 & Answer 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import get_buffer_string\n",
    "\n",
    "# Extract context\n",
    "extract_instructions = \"\"\"You will be given a conversation between an analyst and an expert.\n",
    "\n",
    "Your goal is to help the expert answer the analyst's questions by providing context.\n",
    "\n",
    "Your target assets:\n",
    "{asset_names}.\n",
    "\n",
    "Your task:\n",
    "\n",
    "1. Analyze the full conversation and pay particular attention to the analyst's last message, which contains sub-questions.\n",
    "2. Extract important context for each sub-question from table (`## Contexts` header).\n",
    "   Follow these guidelines:\n",
    "    - Handle ALL sub-questions posed by the analyst at last turn, one by one.\n",
    "    - When there is no context to extract, DO NOT make up any context and just return \"No context for this sub-question!\".\n",
    "3. Include the source (`### Source` header).\n",
    "\n",
    "Output format:\n",
    "\n",
    "1. Include no preamble.\n",
    "2. Use markdown formatting and follow this structure:\n",
    "\n",
    "   ## Contexts\n",
    "   1. [Question] <Follow-up question>\n",
    "   2. [Sub-questions]\n",
    "      [Sub-question 1] <First sub-question>: <Context for first sub-question>\n",
    "      [Sub-question 2] <Second sub-question>: <Context for second sub-question>\n",
    "      [Sub-question 3] <Third sub-question>: <Context for third sub-question>.\n",
    "   ### Source\n",
    "   <Source> or None (e.g., [Table 101]. DO NOT use this format: [1].).\n",
    "\n",
    "Final review:\n",
    "\n",
    "1. Confirm that the task guidelines are all satisfied.\n",
    "2. Confirm that the output format guidelines are all satisfied.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Equity and volatility indicator\n",
    "extract_101_instructions = extract_instructions + \"\"\"Available source:\n",
    "\n",
    "Table 101 has explanatory variables related to equity and volatility indicator.\n",
    "\n",
    "Explanatory variables:\n",
    "{var_dict}.\n",
    "\n",
    "Table data:\n",
    "{table_data}.\"\"\"\n",
    "\n",
    "# Government bond yield\n",
    "extract_102_instructions = extract_instructions + \"\"\"Available source:\n",
    "\n",
    "Table 102 has explanatory variables related to government bond yield.\n",
    "\n",
    "Explanatory variables:\n",
    "{var_dict}.\n",
    "\n",
    "Table data:\n",
    "{table_data}.\"\"\"\n",
    "\n",
    "# Commodities and Futures\n",
    "extract_103_instructions = extract_instructions + \"\"\"Available source:\n",
    "\n",
    "Table 103 has explanatory variables related to commodities and futures.\n",
    "\n",
    "Explanatory variables:\n",
    "{var_dict}.\n",
    "\n",
    "Table data:\n",
    "{table_data}.\"\"\"\n",
    "\n",
    "# Currency exchange rates\n",
    "extract_104_instructions = extract_instructions + \"\"\"Available source:\n",
    "\n",
    "Table 104 has explanatory variables related to currency exchange rates.\n",
    "\n",
    "Explanatory variables:\n",
    "{var_dict}.\n",
    "\n",
    "Table data:\n",
    "{table_data}.\"\"\"\n",
    "\n",
    "# Market index\n",
    "extract_105_instructions = extract_instructions + \"\"\"Available source:\n",
    "\n",
    "Table 105 has explanatory variables related to market index.\n",
    "\n",
    "Explanatory variables:\n",
    "{var_dict}.\n",
    "\n",
    "Table data:\n",
    "{table_data}.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DSC101TH\n",
    "def search_equity_and_volatility(state: InterviewState):\n",
    "    \"\"\" Extract context from table \"\"\"\n",
    "\n",
    "    # Get state\n",
    "    messages = state['messages']\n",
    "    \n",
    "    # LLM\n",
    "    system_message = extract_101_instructions.format(\n",
    "        asset_names=asset_names,\n",
    "        var_dict=var_dict_101,\n",
    "        table_data=table_101_data\n",
    "        )\n",
    "    # structured_llm = llm.with_structured_output(SearchQuery)\n",
    "    extract_result = llm.invoke(\n",
    "        [SystemMessage(content=system_message)] +\n",
    "        messages\n",
    "        )\n",
    "    \n",
    "    return {\"context\": [extract_result.content]}\n",
    "\n",
    "# DSC102TH\n",
    "def search_government_bond_yield(state: InterviewState):\n",
    "    \"\"\" Extract context from table \"\"\"\n",
    "\n",
    "    # Get state\n",
    "    messages = state['messages']\n",
    "    \n",
    "    # LLM\n",
    "    system_message = extract_102_instructions.format(\n",
    "        asset_names=asset_names,\n",
    "        var_dict=var_dict_102,\n",
    "        table_data=table_102_data\n",
    "        )\n",
    "    # structured_llm = llm.with_structured_output(SearchQuery)\n",
    "    extract_result = llm.invoke(\n",
    "        [SystemMessage(content=system_message)] +\n",
    "        messages\n",
    "        )\n",
    "    \n",
    "    return {\"context\": [extract_result.content]}\n",
    "\n",
    "# DSC103TH\n",
    "def search_commodities_and_futures(state: InterviewState):\n",
    "    \"\"\" Extract context from table \"\"\"\n",
    "\n",
    "    # Get state\n",
    "    messages = state['messages']\n",
    "    \n",
    "    # LLM\n",
    "    system_message = extract_103_instructions.format(\n",
    "        asset_names=asset_names,\n",
    "        var_dict=var_dict_103,\n",
    "        table_data=table_103_data\n",
    "        )\n",
    "    # structured_llm = llm.with_structured_output(SearchQuery)\n",
    "    extract_result = llm.invoke(\n",
    "        [SystemMessage(content=system_message)] +\n",
    "        messages\n",
    "        )\n",
    "    \n",
    "    return {\"context\": [extract_result.content]}\n",
    "\n",
    "# DSC104TH\n",
    "def search_currency_exchange_rates(state: InterviewState):\n",
    "    \"\"\" Extract context from table \"\"\"\n",
    "\n",
    "    # Get state\n",
    "    messages = state['messages']\n",
    "    \n",
    "    # LLM\n",
    "    system_message = extract_104_instructions.format(\n",
    "        asset_names=asset_names,\n",
    "        var_dict=var_dict_104,\n",
    "        table_data=table_104_data\n",
    "        )\n",
    "    # structured_llm = llm.with_structured_output(SearchQuery)\n",
    "    extract_result = llm.invoke(\n",
    "        [SystemMessage(content=system_message)] +\n",
    "        messages\n",
    "        )\n",
    "    \n",
    "    return {\"context\": [extract_result.content]}\n",
    "\n",
    "# DSC105TH\n",
    "def search_market_index(state: InterviewState):\n",
    "    \"\"\" Extract context from table \"\"\"\n",
    "\n",
    "    # Get state\n",
    "    messages = state['messages']\n",
    "    \n",
    "    # LLM\n",
    "    system_message = extract_105_instructions.format(\n",
    "        asset_names=asset_names,\n",
    "        var_dict=var_dict_105,\n",
    "        table_data=table_105_data\n",
    "        )\n",
    "    # structured_llm = llm.with_structured_output(SearchQuery)\n",
    "    extract_result = llm.invoke(\n",
    "        [SystemMessage(content=system_message)] +\n",
    "        messages\n",
    "        )\n",
    "    \n",
    "    return {\"context\": [extract_result.content]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_instructions = \"\"\"You are an expert being interviewed by an analyst.\n",
    "\n",
    "Your goal is to answer the analyst's questions based on the provided context.\n",
    "\n",
    "Your target assets:\n",
    "{asset_names}.\n",
    "\n",
    "Your explanation target (AI model result):\n",
    "{AI_model_result}.\n",
    "\n",
    "Analyst's persona:\n",
    "{persona}.\n",
    "\n",
    "Your task:\n",
    "\n",
    "1. Analyze the full conversation and pay particular attention to the analyst's last message, which contains sub-questions.\n",
    "2. Answer the questions (`## Answer` header).\n",
    "   Follow these guidelines:\n",
    "    - Answer all sub-questions posed by the analyst at last turn, one by one, using the provided context.\n",
    "     (Caution: DO NOT handle just single sub-quesiton.)\n",
    "    - Only use the provided context. When the provided context is insufficient, DO NOT make up any answer and just mention that more context is necessary.\n",
    "     (Caution: DO NOT leverage external or unknown contexts that are not provided.)\n",
    "    - Include the source next to any relevant statements (e.g., for Table 102 use [Table 102].).\n",
    "    - Create a list of sources (`### Sources` header).\n",
    "    \n",
    "Output format:\n",
    "\n",
    "1. Include no preamble.\n",
    "2. Use markdown formatting and follow this structure:\n",
    "\n",
    "   ## Answer\n",
    "   [Sub-question 1] <First sub-question>: <Answer for first sub-question>\n",
    "   [Sub-question 2] <Second sub-question>: <Answer for second sub-question>\n",
    "   [Sub-question 3] <Third sub-question>: <Answer for third sub-question>\n",
    "   ### Sources\n",
    "   <Source 1>, <Source 2>, etc. (e.g., [Table 101], [Table 102]. DO NOT use this format: [1], [2].).\n",
    "\n",
    "Final review:\n",
    "\n",
    "1. Confirm that the task guidelines are all satisfied.\n",
    "2. Confirm that the output format guidelines are all satisfied.\n",
    "\n",
    "Provided context:\n",
    "{context}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(state: InterviewState):\n",
    "    \"\"\" Node to answer a question \"\"\"\n",
    "\n",
    "    # Get state\n",
    "    analyst = state[\"analyst\"]\n",
    "    context = state[\"context\"]\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    # LLM\n",
    "    system_message = answer_instructions.format(\n",
    "        asset_names=asset_names,\n",
    "        AI_model_result=AI_model_result,\n",
    "        persona=analyst.persona,\n",
    "        context=context\n",
    "        )\n",
    "    answer = llm.invoke(\n",
    "        [SystemMessage(content=system_message)] +\n",
    "        messages\n",
    "        )\n",
    "    \n",
    "    # Name the message as coming from the expert\n",
    "    answer.name = \"expert\"\n",
    "    \n",
    "    return {\"messages\": [answer]}\n",
    "\n",
    "def save_interview(state: InterviewState):\n",
    "    \"\"\" Save interviews \"\"\"\n",
    "\n",
    "    # Get state\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # Convert interview to a string\n",
    "    interview = get_buffer_string(messages)\n",
    "    \n",
    "    return {\"interview\": interview}\n",
    "\n",
    "def route_messages(state: InterviewState, \n",
    "                   name: str = \"expert\"):\n",
    "    \"\"\" Route between question and answer \"\"\"\n",
    "    \n",
    "    # Get state\n",
    "    messages = state[\"messages\"]\n",
    "    max_num_turns = state[\"max_num_turns\"]\n",
    "\n",
    "    # Check the number of expert answers \n",
    "    num_responses = len(\n",
    "        [m for m in messages if isinstance(m, AIMessage) and m.name == name]\n",
    "    )\n",
    "\n",
    "    # End if expert has answered more than the max turns\n",
    "    if num_responses >= max_num_turns:\n",
    "        return 'save_interview'\n",
    "\n",
    "    # This router is run after each question - answer pair \n",
    "    # Get the last question asked to check if it signals the end of discussion\n",
    "    last_question = messages[-2]\n",
    "    \n",
    "    if \"I'd like to finish my interview with expert since I'm ready for impressive explanation!\" in last_question.content:\n",
    "        return 'save_interview'\n",
    "    \n",
    "    return \"ask_question\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Section 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_writer_instructions = \"\"\"You are a technical writer specializing in the finance field.\n",
    "\n",
    "Your goal is to write a section based on the provided interview transcript.\n",
    "\n",
    "Your task:\n",
    "\n",
    "1. Review the information of interviewer:\n",
    "{description}\n",
    "2. Create a narrative by gathering and understanding valid sub-question and answer pairs from the interview transcript.\n",
    "3. Write Body part (`## Section` header).\n",
    "   Follow these guidelines:\n",
    "    - DO NOT mention any interviewer and interviewee names.\n",
    "    - Aim for approximately 500 words maximum and 3 paragraphs with sub-title (`### Sub-title` header). Keep the flow of the interview as close as possible.\n",
    "     (Caution: DO NOT over-abbreviate original meaningful insights and figures.)\n",
    "    - Preserve all the existing specific figures and sources in the interviewee's answer.\n",
    "     (Caution: When making a new sentence by combining sentences with explicit source, include the new source next to this made-up sentence. It can be multiple sources like [Table 101], [Table 102].).\n",
    "4. Write Sources part (`### Sources` header).\n",
    "   Follow these guidelines:\n",
    "    - Create a list of sources.\n",
    "    - Be sure that there is no redundant sources.\n",
    "\n",
    "Output format:\n",
    "\n",
    "1. Include no preamble.\n",
    "2. Use markdown formatting and follow this structure:\n",
    "    ## Section\n",
    "    ### Sub-title 1\n",
    "    ### Sub-title 2\n",
    "    ### Sub-title 3\n",
    "    ### Sources (e.g., [Table 101], [Table 102]. DO NOT use this format: [1], [2].).\n",
    "\n",
    "Final review:\n",
    "\n",
    "1. Confirm that the task guidelines are all satisfied.\n",
    "2. Confirm that the output format guidelines are all satisfied.\"\"\"\n",
    "\n",
    "def write_section(state: InterviewState):\n",
    "    \"\"\" Node to answer a question \"\"\"\n",
    "\n",
    "    # Get state\n",
    "    interview = state[\"interview\"]\n",
    "    analyst = state[\"analyst\"]\n",
    "    \n",
    "    # LLM (use context)\n",
    "    system_message = section_writer_instructions.format(description=analyst.description)\n",
    "    section = llm.invoke(\n",
    "        [SystemMessage(content=system_message)] +\n",
    "        [HumanMessage(content=f\"Use this interview transcript to write your section: {interview}\")]\n",
    "        ) \n",
    "    \n",
    "    # Append it to state\n",
    "    return {\"sections\": [section.content]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add nodes and edges \n",
    "interview_builder = StateGraph(InterviewState)\n",
    "interview_builder.add_node(\"ask_question\", generate_question)\n",
    "interview_builder.add_node(\"search_equity_and_volatility\", search_equity_and_volatility)\n",
    "interview_builder.add_node(\"search_government_bond_yield\", search_government_bond_yield)\n",
    "interview_builder.add_node(\"search_commodities_and_futures\", search_commodities_and_futures)\n",
    "interview_builder.add_node(\"search_currency_exchange_rates\", search_currency_exchange_rates)\n",
    "interview_builder.add_node(\"search_market_index\", search_market_index)\n",
    "interview_builder.add_node(\"answer_question\", generate_answer)\n",
    "interview_builder.add_node(\"save_interview\", save_interview)\n",
    "interview_builder.add_node(\"write_section\", write_section)\n",
    "\n",
    "# Flow\n",
    "interview_builder.add_edge(START, \"ask_question\")\n",
    "interview_builder.add_edge(\"ask_question\", \"search_equity_and_volatility\")\n",
    "interview_builder.add_edge(\"ask_question\", \"search_government_bond_yield\")\n",
    "interview_builder.add_edge(\"ask_question\", \"search_commodities_and_futures\")\n",
    "interview_builder.add_edge(\"ask_question\", \"search_currency_exchange_rates\")\n",
    "interview_builder.add_edge(\"ask_question\", \"search_market_index\")\n",
    "interview_builder.add_edge(\"search_equity_and_volatility\", \"answer_question\")\n",
    "interview_builder.add_edge(\"search_government_bond_yield\", \"answer_question\")\n",
    "interview_builder.add_edge(\"search_commodities_and_futures\", \"answer_question\")\n",
    "interview_builder.add_edge(\"search_currency_exchange_rates\", \"answer_question\")\n",
    "interview_builder.add_edge(\"search_market_index\", \"answer_question\")\n",
    "interview_builder.add_conditional_edges(\"answer_question\", route_messages, ['ask_question', 'save_interview'])\n",
    "interview_builder.add_edge(\"save_interview\", \"write_section\")\n",
    "interview_builder.add_edge(\"write_section\", END)\n",
    "\n",
    "# Interview \n",
    "memory = MemorySaver()\n",
    "interview_graph = interview_builder.compile(checkpointer=memory).with_config(run_name=\"Conduct Interviews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-3. Interview 수행 (Parallelization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.constants import Send\n",
    "\n",
    "# Conditional edge\n",
    "def initiate_all_interviews(state: ResearchGraphState):\n",
    "    \"\"\" This is the \"map\" step where we run each interview sub-graph using Send API \"\"\"    \n",
    "\n",
    "    # Check if human feedback\n",
    "    human_analyst_feedback = state.get('human_analyst_feedback')\n",
    "    if human_analyst_feedback:\n",
    "        # Return to create_analysts\n",
    "        return \"create_analysts\"\n",
    "\n",
    "    # Otherwise kick off interviews in parallel via Send() API\n",
    "    else:\n",
    "        messages = [HumanMessage(content=\"So you said you were explaining the AI model result of portfolio optimization?\")]\n",
    "        return [Send(\"conduct_interview\",\n",
    "                     {\"analyst\": analyst,\n",
    "                      \"max_num_turns\": max_num_turns,\n",
    "                      \"messages\": messages}) for analyst in state[\"analysts\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-4. Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter_instructions = \"\"\"You are a certified investment manager with extensive finance field experience.\n",
    "\n",
    "Your goal is to interpret the AI model result of portfolio optimization from your professional perspective and data.\n",
    "\n",
    "It is extremely important to focus on on high-level themes such as market dynamics, fund flows, and potential risks.\n",
    "\n",
    "Your target assets:\n",
    "{asset_names}.\n",
    "\n",
    "Your explanation target (AI model result):\n",
    "{AI_model_result}.\n",
    "\n",
    "Your task:\n",
    "\n",
    "1. Analyze all the sections written from the interview result.\n",
    "   A team of analysts conducted interview. Each analyst has done two things: \n",
    "    - They conducted an interview with an expert.\n",
    "    - They wrote up their finding into a section.\n",
    "2. Think carefully about the provided sections.\n",
    "3. Consolidate the insights from all the sections to come up with high-level insights.\n",
    "4. Create a holistic narrative that reflects your persona and connects the insights together.\n",
    "   This holistic narrative focuses on high-level themes such as market dynamics, fund flows, and potential risks.\n",
    "5. Write Body part (`## Interpretation` header).\n",
    "   Follow these guidelines:\n",
    "    - Focus on the provided sections. When necessary, you can additionally leverage your own knowledge.\n",
    "    - Emphasize the novelty of your insights.\n",
    "    - DO NOT mention any imaginary names.\n",
    "    - Aim for approximately 750 words maximum and 3 paragraphs with sub-title (`### Sub-title` header). Each paragraph should correspond to individual explanation target.\n",
    "     (Caution: Avoid vague phrases that are not specific and have no impact. DO NOT over-abbreviate original meaningful insights and figures.)\n",
    "    - Preserve all the existing specific figures and sources in the provided sections.\n",
    "     (Caution: When making a new sentence by combining sentences with explicit sources, include the new source next to this made-up sentence. It can be multiple sources like [Table 101], [Table 102].).\n",
    "6. Write Sources part (`### Sources` header).\n",
    "   Follow these guidelines:\n",
    "    - Create a list of sources.\n",
    "    - Be sure that there is no redundant sources.\n",
    "7. Come up with an engaging and focused title (`# Title` header).\n",
    "  (Caution: Avoid vague phrases that are not specific and have no impact.)\n",
    "  \n",
    "Output format:\n",
    "\n",
    "1. Include no preamble.\n",
    "2. Use markdown formatting and follow this structure:\n",
    "    # Title\n",
    "    ## Interpretation\n",
    "    ### Sub-title 1\n",
    "    ### Sub-title 2\n",
    "    ### Sub-title 3\n",
    "    ### Sources.\n",
    "\n",
    "Final review:\n",
    "\n",
    "1. Confirm that the task guidelines are all satisfied.\n",
    "2. Confirm that the output format guidelines are all satisfied.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "interpreter_risk_seeking_instructions = interpreter_instructions + \"\"\"Your persona:\n",
    "\n",
    "1. You are a certified investment manager and need to explain the AI model result of portfolio optimization to your customers.\n",
    "2. Your customors have risk-seeking investment style: risk-seeking level is 5/5.\"\"\"\n",
    "\n",
    "interpreter_stability_seeking_instructions = interpreter_instructions + \"\"\"Your persona:\n",
    "\n",
    "1. You are a certified investment manager and need to explain the AI model result of portfolio optimization to your customers.\n",
    "2. Your customors have stability-seeking investment style: risk-seeking level is 4/5.\"\"\"\n",
    "\n",
    "interpreter_balanced_instructions = interpreter_instructions + \"\"\"Your persona:\n",
    "\n",
    "1. You are a certified investment manager and need to explain the AI model result of portfolio optimization to your customers.\n",
    "2. Your customors have balanced investment style: risk-seeking level is 3/5.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_risk_seeking(state: ResearchGraphState):\n",
    "    # Full set of sections\n",
    "    sections = state[\"sections\"]\n",
    "\n",
    "    # Concat all sections together\n",
    "    formatted_str_sections = \"\\n\\n\".join([f\"{section}\" for section in sections])\n",
    "    \n",
    "    # LLM\n",
    "    system_message = interpreter_risk_seeking_instructions.format(\n",
    "        asset_names=asset_names,\n",
    "        AI_model_result=AI_model_result)    \n",
    "    interpretation = llm.invoke(\n",
    "        [SystemMessage(content=system_message)] + \n",
    "        [HumanMessage(content=f\"Write interpretation based on the written sections. Here are the sections: {formatted_str_sections}\")])\n",
    "    \n",
    "    return {\"interpretations\": [interpretation.content]}\n",
    "\n",
    "def interpret_stability_seeking(state: ResearchGraphState):\n",
    "    # Full set of sections\n",
    "    sections = state[\"sections\"]\n",
    "\n",
    "    # Concat all sections together\n",
    "    formatted_str_sections = \"\\n\\n\".join([f\"{section}\" for section in sections])\n",
    "    \n",
    "    # LLM\n",
    "    system_message = interpreter_stability_seeking_instructions.format(\n",
    "        asset_names=asset_names,\n",
    "        AI_model_result=AI_model_result)    \n",
    "    interpretation = llm.invoke(\n",
    "        [SystemMessage(content=system_message)] + \n",
    "        [HumanMessage(content=f\"Write interpretation based on the written sections. Here are the sections: {formatted_str_sections}\")])\n",
    "    \n",
    "    return {\"interpretations\": [interpretation.content]}\n",
    "\n",
    "def interpret_balanced(state: ResearchGraphState):\n",
    "    # Full set of sections\n",
    "    sections = state[\"sections\"]\n",
    "\n",
    "    # Concat all sections together\n",
    "    formatted_str_sections = \"\\n\\n\".join([f\"{section}\" for section in sections])\n",
    "    \n",
    "    # LLM\n",
    "    system_message = interpreter_balanced_instructions.format(\n",
    "        asset_names=asset_names,\n",
    "        AI_model_result=AI_model_result)    \n",
    "    interpretation = llm.invoke(\n",
    "        [SystemMessage(content=system_message)] + \n",
    "        [HumanMessage(content=f\"Write interpretation based on the written sections. Here are the sections: {formatted_str_sections}\")])\n",
    "    \n",
    "    return {\"interpretations\": [interpretation.content]}    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-5. Report 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_writer_instructions = \"\"\"You are a technical writer specializing in the finance field.\n",
    "\n",
    "Your goal is to write a technical report that explains the AI model result of portfolio optimization by integrating the provided interpretations.\n",
    "\n",
    "It is extremely important to focus on on high-level themes such as market dynamics, fund flows, and potential risks.\n",
    "\n",
    "Your target assets:\n",
    "{asset_names}.\n",
    "\n",
    "Your explanation target (AI model result):\n",
    "{AI_model_result}.\n",
    "\n",
    "Your task:\n",
    "\n",
    "1. Analyze all the interpretations provided by several certified investment managers with diverse investment style.\n",
    "2. Think carefully about the provided interpretations.\n",
    "3. Consolidate the insights from all the interpretations to come up with impressive and powerful conclusion.\n",
    "4. Create a holistic narrative that reflects your persona and connects the insights together.\n",
    "   This holistic narrative focuses on high-level themes such as market dynamics, fund flows, and potential risks.\n",
    "5. Write Body part (`## Analysis` header).\n",
    "   Follow these guidelines:\n",
    "    - Assume readers with profound knowledge and diverse investment style.\n",
    "    - Tone and manner must be technical and clear.\n",
    "    - Begin by briefly summarizing 3 explanation targets (`### Target` header).\n",
    "    - Emphasize the novelty of your insights.\n",
    "    - DO NOT mention any imaginary names.\n",
    "    - Aim for approximately 750 words maximum and 3 paragraphs with sub-title (`### Sub-title` header). Each paragraph should correspond to individual explanation target.\n",
    "     (Caution: Avoid vague phrases that are not specific and have no impact. DO NOT over-abbreviate original meaningful insights and figures.)\n",
    "    - Preserve all the existing specific figures and sources in the provided interpretations.\n",
    "     (Caution: When making a new sentence by combining sentences with explicit sources, include the new source next to this made-up sentence. It can be multiple sources like [Table 101], [Table 102].).\n",
    "6. Write Sources part (`### Sources` header).\n",
    "   Follow these guidelines:\n",
    "    - Create a list of sources.\n",
    "    - Be sure that there is no redundant sources.\n",
    "7. Come up with an engaging and focused title (`# Title` header).\n",
    "  (Caution: Avoid vague phrases that are not specific and have no impact.)\n",
    "8. Provide the original English version AND Korean version report.\n",
    "\n",
    "Output format:\n",
    "\n",
    "1. Include no preamble.\n",
    "2. For English version, use markdown formatting and follow this structure:\n",
    "    # Title\n",
    "    ## Analysis\n",
    "    ### Target\n",
    "    ### Sub-title 1\n",
    "    ### Sub-title 2\n",
    "    ### Sub-title 3\n",
    "    ### Sources.\n",
    "3. 한국어 버전에 마크다운 포맷을 적용하고 다음 구조를 따르세요:\n",
    "    # 제목\n",
    "    ## 분석\n",
    "    ### 타겟\n",
    "    ### 소제목 1\n",
    "    ### 소제목 2\n",
    "    ### 소제목 3\n",
    "    ### 출처.\n",
    "    \n",
    "Final review:\n",
    "\n",
    "1. Confirm that the task guidelines are all satisfied.\n",
    "2. Confirm that the output format guidelines are all satisfied.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_report(state: ResearchGraphState):\n",
    "    # Full set of interpretations\n",
    "    interpretations = state[\"interpretations\"]\n",
    "    \n",
    "    # Concat all interpretations together\n",
    "    formatted_str_interpretations = \"\\n\\n\".join([f\"{interpretation}\" for interpretation in interpretations])\n",
    "    \n",
    "    # LLM\n",
    "    system_message = report_writer_instructions.format(\n",
    "        asset_names=asset_names,\n",
    "        AI_model_result=AI_model_result)    \n",
    "    report = llm.invoke(\n",
    "        [SystemMessage(content=system_message)] + \n",
    "        [HumanMessage(content=f\"Write a report based on the diverse interpretations. Here are the interpretations: {formatted_str_interpretations}\")])\n",
    "    \n",
    "    return {\"content\": report.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add nodes and edges \n",
    "builder = StateGraph(ResearchGraphState)\n",
    "builder.add_node(\"create_analysts\", create_analysts)\n",
    "builder.add_node(\"human_feedback\", human_feedback)\n",
    "builder.add_node(\"conduct_interview\", interview_builder.compile())\n",
    "builder.add_node(\"interpret_risk_seeking\", interpret_risk_seeking)\n",
    "builder.add_node(\"interpret_stability_seeking\", interpret_stability_seeking)\n",
    "builder.add_node(\"interpret_balanced\", interpret_balanced)\n",
    "builder.add_node(\"write_report\", write_report)\n",
    "\n",
    "# Logic\n",
    "builder.add_edge(START, \"create_analysts\")\n",
    "builder.add_edge(\"create_analysts\", \"human_feedback\")\n",
    "builder.add_conditional_edges(\"human_feedback\", initiate_all_interviews, [\"create_analysts\", \"conduct_interview\"])\n",
    "builder.add_edge(\"conduct_interview\", \"interpret_risk_seeking\")\n",
    "builder.add_edge(\"conduct_interview\", \"interpret_stability_seeking\")\n",
    "builder.add_edge(\"conduct_interview\", \"interpret_balanced\")\n",
    "builder.add_edge(\"interpret_risk_seeking\", \"write_report\")\n",
    "builder.add_edge(\"interpret_stability_seeking\", \"write_report\")\n",
    "builder.add_edge(\"interpret_balanced\", \"write_report\")\n",
    "builder.add_edge(\"write_report\", END)\n",
    "\n",
    "# Compile\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(interrupt_before=['human_feedback'], checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-6. 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Emma Thompson\n",
      "Affiliation: International Financial Advisory Group\n",
      "Role: Global Market Strategist\n",
      "Description: Emma focuses on global market dynamics, analyzing how equity and volatility indicators interact with government bond yields to influence portfolio optimization. She is particularly interested in how shifts in major indices like the DAX and FTSE 100, combined with bond yield movements, can signal broader economic trends and impact asset allocation strategies.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Name: Liam Chen\n",
      "Affiliation: Global Commodities Research Institute\n",
      "Role: Commodities Analyst\n",
      "Description: Liam specializes in the commodities and futures markets, examining how fluctuations in key commodities like gold, copper, and crude oil affect portfolio performance. He explores the interplay between commodity prices and equity markets, assessing how these relationships can inform risk management and diversification strategies.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Name: Sophia Martinez\n",
      "Affiliation: Bond Market Insights\n",
      "Role: Fixed Income Specialist\n",
      "Description: Sophia's expertise lies in government bond yields and their implications for portfolio optimization. She analyzes how changes in yields across different countries, such as the US, China, and Germany, influence investment decisions and risk assessments. Her focus is on understanding the macroeconomic factors driving yield movements and their impact on equity markets.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Name: Noah Patel\n",
      "Affiliation: Forex and Macro Trends\n",
      "Role: Currency Market Analyst\n",
      "Description: Noah examines the influence of currency exchange rates on global investment strategies, focusing on how currency fluctuations can affect international portfolio returns. He provides insights into how exchange rate movements, particularly involving the USD, Euro, and emerging market currencies, can impact asset performance and investor sentiment.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Name: Ava Johnson\n",
      "Affiliation: Risk Management Solutions\n",
      "Role: Volatility and Risk Analyst\n",
      "Description: Ava is dedicated to understanding market volatility and its implications for portfolio risk management. She analyzes volatility indices, such as the VIX and VDAX, to assess market sentiment and potential risks. Her work involves developing strategies to mitigate volatility-related risks and enhance portfolio resilience in uncertain market conditions.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Run the graph until the first interruption\n",
    "for event in graph.stream({\"analysts\": analysts}, # {\"max_analysts\": max_analysts}\n",
    "                          thread, \n",
    "                          stream_mode=\"values\"):\n",
    "    \n",
    "    analysts = event.get('analysts', '')\n",
    "    if analysts:\n",
    "        for analyst in analysts:\n",
    "            print(f\"Name: {analyst.name}\")\n",
    "            print(f\"Affiliation: {analyst.affiliation}\")\n",
    "            print(f\"Role: {analyst.role}\")\n",
    "            print(f\"Description: {analyst.description}\")\n",
    "            print(\"-\" * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1efb946a-b534-6f3e-8002-b9f542f78b65'}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm we are happy\n",
    "further_feedack = None\n",
    "graph.update_state(\n",
    "    thread,\n",
    "    {\"human_analyst_feedback\": further_feedack},\n",
    "    as_node=\"human_feedback\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Node--\n",
      "conduct_interview\n",
      "--Node--\n",
      "conduct_interview\n",
      "--Node--\n",
      "conduct_interview\n",
      "--Node--\n",
      "conduct_interview\n",
      "--Node--\n",
      "conduct_interview\n",
      "--Node--\n",
      "interpret_stability_seeking\n",
      "--Node--\n",
      "interpret_risk_seeking\n",
      "--Node--\n",
      "interpret_balanced\n",
      "--Node--\n",
      "write_report\n"
     ]
    }
   ],
   "source": [
    "# Continue\n",
    "for event in graph.stream(None, thread, stream_mode=\"updates\"):\n",
    "    print(\"--Node--\")\n",
    "    node_name = next(iter(event.keys()))\n",
    "    print(node_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Portfolio Reallocation and Market Dynamics: November 2024\n",
       "\n",
       "## Analysis\n",
       "\n",
       "### Target\n",
       "\n",
       "The AI model results indicate three key observations regarding portfolio optimization for the target assets: a significant drop in asset group weights on November 20, 2024, a consistent increase in asset group weights prior to this date, and the unique behavior of AA-ETF_EQUITY-SUSL on the same date. These observations reflect underlying market dynamics, fund flows, and potential risks that influenced investment strategies during this period.\n",
       "\n",
       "### Market Volatility and Asset Reallocation\n",
       "\n",
       "The significant drop in asset group weights on November 20, 2024, is a strategic response to heightened market volatility and shifting investor sentiment. The increase in the CBOE SPX Volatility VIX (NEW) index from 15.58 to 17.16 during this period indicates a rise in market uncertainty, prompting investors to reassess their risk exposure [Table 101]. This volatility, coupled with a slight decrease in the Refinitiv United States Government Benchmark Bid Yield 10 Years from 4.416 to 4.388, suggests a shift towards safer investments, as investors sought refuge in lower-risk assets amidst the volatile environment [Table 102]. Additionally, fluctuations in commodity markets, such as the increase in the CBOE GOLD VOLATILITY INDEX from 16.97 to 18.34, further contributed to the reallocation of assets, as investors adjusted their portfolios to mitigate potential risks [Table 101]. These market dynamics collectively underscore the importance of maintaining a flexible investment strategy that can adapt to evolving conditions, particularly in times of increased volatility.\n",
       "\n",
       "### Factors Driving Asset Weight Increases\n",
       "\n",
       "Prior to the significant drop on November 20, 2024, asset group weights had been on a consistent upward trajectory, driven by favorable market conditions and positive investor sentiment. The robust performance of major equity indices, such as the CME-Standard and Poors 500 Index Composite CS02, which rose from 5608.25 to 5916.98, reflects a bullish trend in the equity market, encouraging increased exposure to equities [Table 101]. Additionally, the downward trend in the Refinitiv China Government Benchmark Bid Yield 10 Years from 2.183 to 2.091 suggests a shift away from bonds towards equities, as investors capitalized on the favorable conditions for equity investments [Table 102]. The appreciation of the Brazilian Real against the US Dollar, with the exchange rate moving from 5.4785 to 5.77275, also influenced investment strategies, as investors sought to benefit from currency movements [Table 104]. These factors collectively contributed to the increase in asset group weights, as investors sought to capitalize on market opportunities and optimize their portfolios.\n",
       "\n",
       "### Unique Behavior of AA-ETF_EQUITY-SUSL\n",
       "\n",
       "The unique behavior of AA-ETF_EQUITY-SUSL on November 20, 2024, where it increased in weight while other asset groups experienced a decline, can be attributed to specific market dynamics and currency fluctuations. The strengthening of the United States Dollar against the Euro, with the exchange rate declining from 1.11305 to 1.0544, made US-based assets more attractive to international investors, potentially explaining the increased weight of AA-ETF_EQUITY-SUSL [Table 104]. Additionally, the slight decrease in the Refinitiv United States Government Benchmark Bid Yield 3 Years from 4.277 to 4.237 may have influenced investor decisions, as they sought to adjust their portfolios in response to changing interest rate expectations [Table 102]. These factors highlight the importance of considering currency movements and interest rate trends when making investment decisions, as they can significantly impact the relative attractiveness of different asset classes and influence portfolio allocations.\n",
       "\n",
       "### Sources\n",
       "\n",
       "[Table 101], [Table 102], [Table 103], [Table 104].\n",
       "\n",
       "# 포트폴리오 재배치 및 시장 역학: 2024년 11월\n",
       "\n",
       "## 분석\n",
       "\n",
       "### 타겟\n",
       "\n",
       "AI 모델 결과는 대상 자산에 대한 포트폴리오 최적화와 관련하여 세 가지 주요 관찰을 나타냅니다: 2024년 11월 20일에 자산 그룹 가중치의 상당한 하락, 이 날짜 이전의 자산 그룹 가중치의 일관된 증가, 그리고 같은 날짜에 AA-ETF_EQUITY-SUSL의 독특한 행동입니다. 이러한 관찰은 이 기간 동안 투자 전략에 영향을 미친 기본적인 시장 역학, 자금 흐름 및 잠재적 위험을 반영합니다.\n",
       "\n",
       "### 시장 변동성과 자산 재배치\n",
       "\n",
       "2024년 11월 20일에 자산 그룹 가중치의 상당한 하락은 시장 변동성 증가와 투자자 심리 변화에 대한 전략적 대응입니다. 이 기간 동안 CBOE SPX Volatility VIX (NEW) 지수가 15.58에서 17.16으로 증가한 것은 시장 불확실성이 증가했음을 나타내며, 이는 투자자들이 위험 노출을 재평가하도록 촉발했습니다 [Table 101]. 이러한 변동성과 함께 Refinitiv 미국 정부 벤치마크 입찰 수익률 10년물이 4.416에서 4.388로 약간 감소한 것은 투자자들이 변동성이 큰 환경 속에서 더 안전한 자산으로 피신하려는 움직임을 시사합니다 [Table 102]. 또한, CBOE GOLD VOLATILITY INDEX가 16.97에서 18.34로 증가하는 등 상품 시장의 변동성은 투자자들이 잠재적 위험을 완화하기 위해 포트폴리오를 조정함에 따라 자산 재배치에 기여했습니다 [Table 101]. 이러한 시장 역학은 특히 변동성이 증가하는 시기에 진화하는 조건에 적응할 수 있는 유연한 투자 전략을 유지하는 것의 중요성을 강조합니다.\n",
       "\n",
       "### 자산 가중치 증가를 이끄는 요인\n",
       "\n",
       "2024년 11월 20일의 상당한 하락 이전에 자산 그룹 가중치는 유리한 시장 조건과 긍정적인 투자자 심리에 의해 일관되게 증가했습니다. CME-Standard and Poors 500 Index Composite CS02와 같은 주요 주식 지수의 강력한 성과는 주식 시장의 강세 추세를 반영하며, 주식에 대한 노출을 증가시키도록 장려했습니다 [Table 101]. 또한, Refinitiv 중국 정부 벤치마크 입찰 수익률 10년물이 2.183에서 2.091로 하락하는 추세는 투자자들이 주식 투자에 유리한 조건을 활용함에 따라 채권에서 주식으로의 이동을 시사합니다 [Table 102]. 브라질 레알이 미국 달러 대비 5.4785에서 5.77275로 평가 절상된 것도 투자 전략에 영향을 미쳤으며, 투자자들이 통화 움직임에서 이익을 얻으려 했습니다 [Table 104]. 이러한 요인들은 투자자들이 시장 기회를 활용하고 포트폴리오를 최적화하려고 함에 따라 자산 그룹 가중치 증가에 기여했습니다.\n",
       "\n",
       "### AA-ETF_EQUITY-SUSL의 독특한 행동\n",
       "\n",
       "2024년 11월 20일에 다른 자산 그룹이 하락을 경험한 반면 AA-ETF_EQUITY-SUSL의 가중치가 증가한 독특한 행동은 특정 시장 역학과 통화 변동에 기인할 수 있습니다. 미국 달러가 유로 대비 강세를 보이며 환율이 1.11305에서 1.0544로 하락한 것은 국제 투자자들에게 미국 기반 자산을 더 매력적으로 만들었을 가능성이 있으며, 이는 AA-ETF_EQUITY-SUSL의 가중치 증가를 설명할 수 있습니다 [Table 104]. 또한, Refinitiv 미국 정부 벤치마크 입찰 수익률 3년물이 4.277에서 4.237로 약간 감소한 것은 투자자들이 금리 기대 변화에 대응하여 포트폴리오를 조정하려 했음을 시사할 수 있습니다 [Table 102]. 이러한 요인은 투자 결정을 내릴 때 통화 움직임과 금리 추세를 고려하는 것의 중요성을 강조하며, 이는 다양한 자산 클래스의 상대적 매력에 크게 영향을 미치고 포트폴리오 할당에 영향을 미칠 수 있습니다.\n",
       "\n",
       "### 출처\n",
       "\n",
       "[Table 101], [Table 102], [Table 103], [Table 104]."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "final_state = graph.get_state(thread)\n",
    "report = final_state.values.get('content')\n",
    "Markdown(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Portfolio Reallocation and Market Dynamics: November 2024\\n\\n## Analysis\\n\\n### Target\\n\\nThe AI model results indicate three key observations regarding portfolio optimization for the target assets: a significant drop in asset group weights on November 20, 2024, a consistent increase in asset group weights prior to this date, and the unique behavior of AA-ETF_EQUITY-SUSL on the same date. These observations reflect underlying market dynamics, fund flows, and potential risks that influenced investment strategies during this period.\\n\\n### Market Volatility and Asset Reallocation\\n\\nThe significant drop in asset group weights on November 20, 2024, is a strategic response to heightened market volatility and shifting investor sentiment. The increase in the CBOE SPX Volatility VIX (NEW) index from 15.58 to 17.16 during this period indicates a rise in market uncertainty, prompting investors to reassess their risk exposure [Table 101]. This volatility, coupled with a slight decrease in the Refinitiv United States Government Benchmark Bid Yield 10 Years from 4.416 to 4.388, suggests a shift towards safer investments, as investors sought refuge in lower-risk assets amidst the volatile environment [Table 102]. Additionally, fluctuations in commodity markets, such as the increase in the CBOE GOLD VOLATILITY INDEX from 16.97 to 18.34, further contributed to the reallocation of assets, as investors adjusted their portfolios to mitigate potential risks [Table 101]. These market dynamics collectively underscore the importance of maintaining a flexible investment strategy that can adapt to evolving conditions, particularly in times of increased volatility.\\n\\n### Factors Driving Asset Weight Increases\\n\\nPrior to the significant drop on November 20, 2024, asset group weights had been on a consistent upward trajectory, driven by favorable market conditions and positive investor sentiment. The robust performance of major equity indices, such as the CME-Standard and Poors 500 Index Composite CS02, which rose from 5608.25 to 5916.98, reflects a bullish trend in the equity market, encouraging increased exposure to equities [Table 101]. Additionally, the downward trend in the Refinitiv China Government Benchmark Bid Yield 10 Years from 2.183 to 2.091 suggests a shift away from bonds towards equities, as investors capitalized on the favorable conditions for equity investments [Table 102]. The appreciation of the Brazilian Real against the US Dollar, with the exchange rate moving from 5.4785 to 5.77275, also influenced investment strategies, as investors sought to benefit from currency movements [Table 104]. These factors collectively contributed to the increase in asset group weights, as investors sought to capitalize on market opportunities and optimize their portfolios.\\n\\n### Unique Behavior of AA-ETF_EQUITY-SUSL\\n\\nThe unique behavior of AA-ETF_EQUITY-SUSL on November 20, 2024, where it increased in weight while other asset groups experienced a decline, can be attributed to specific market dynamics and currency fluctuations. The strengthening of the United States Dollar against the Euro, with the exchange rate declining from 1.11305 to 1.0544, made US-based assets more attractive to international investors, potentially explaining the increased weight of AA-ETF_EQUITY-SUSL [Table 104]. Additionally, the slight decrease in the Refinitiv United States Government Benchmark Bid Yield 3 Years from 4.277 to 4.237 may have influenced investor decisions, as they sought to adjust their portfolios in response to changing interest rate expectations [Table 102]. These factors highlight the importance of considering currency movements and interest rate trends when making investment decisions, as they can significantly impact the relative attractiveness of different asset classes and influence portfolio allocations.\\n\\n### Sources\\n\\n[Table 101], [Table 102], [Table 103], [Table 104].\\n\\n# 포트폴리오 재배치 및 시장 역학: 2024년 11월\\n\\n## 분석\\n\\n### 타겟\\n\\nAI 모델 결과는 대상 자산에 대한 포트폴리오 최적화와 관련하여 세 가지 주요 관찰을 나타냅니다: 2024년 11월 20일에 자산 그룹 가중치의 상당한 하락, 이 날짜 이전의 자산 그룹 가중치의 일관된 증가, 그리고 같은 날짜에 AA-ETF_EQUITY-SUSL의 독특한 행동입니다. 이러한 관찰은 이 기간 동안 투자 전략에 영향을 미친 기본적인 시장 역학, 자금 흐름 및 잠재적 위험을 반영합니다.\\n\\n### 시장 변동성과 자산 재배치\\n\\n2024년 11월 20일에 자산 그룹 가중치의 상당한 하락은 시장 변동성 증가와 투자자 심리 변화에 대한 전략적 대응입니다. 이 기간 동안 CBOE SPX Volatility VIX (NEW) 지수가 15.58에서 17.16으로 증가한 것은 시장 불확실성이 증가했음을 나타내며, 이는 투자자들이 위험 노출을 재평가하도록 촉발했습니다 [Table 101]. 이러한 변동성과 함께 Refinitiv 미국 정부 벤치마크 입찰 수익률 10년물이 4.416에서 4.388로 약간 감소한 것은 투자자들이 변동성이 큰 환경 속에서 더 안전한 자산으로 피신하려는 움직임을 시사합니다 [Table 102]. 또한, CBOE GOLD VOLATILITY INDEX가 16.97에서 18.34로 증가하는 등 상품 시장의 변동성은 투자자들이 잠재적 위험을 완화하기 위해 포트폴리오를 조정함에 따라 자산 재배치에 기여했습니다 [Table 101]. 이러한 시장 역학은 특히 변동성이 증가하는 시기에 진화하는 조건에 적응할 수 있는 유연한 투자 전략을 유지하는 것의 중요성을 강조합니다.\\n\\n### 자산 가중치 증가를 이끄는 요인\\n\\n2024년 11월 20일의 상당한 하락 이전에 자산 그룹 가중치는 유리한 시장 조건과 긍정적인 투자자 심리에 의해 일관되게 증가했습니다. CME-Standard and Poors 500 Index Composite CS02와 같은 주요 주식 지수의 강력한 성과는 주식 시장의 강세 추세를 반영하며, 주식에 대한 노출을 증가시키도록 장려했습니다 [Table 101]. 또한, Refinitiv 중국 정부 벤치마크 입찰 수익률 10년물이 2.183에서 2.091로 하락하는 추세는 투자자들이 주식 투자에 유리한 조건을 활용함에 따라 채권에서 주식으로의 이동을 시사합니다 [Table 102]. 브라질 레알이 미국 달러 대비 5.4785에서 5.77275로 평가 절상된 것도 투자 전략에 영향을 미쳤으며, 투자자들이 통화 움직임에서 이익을 얻으려 했습니다 [Table 104]. 이러한 요인들은 투자자들이 시장 기회를 활용하고 포트폴리오를 최적화하려고 함에 따라 자산 그룹 가중치 증가에 기여했습니다.\\n\\n### AA-ETF_EQUITY-SUSL의 독특한 행동\\n\\n2024년 11월 20일에 다른 자산 그룹이 하락을 경험한 반면 AA-ETF_EQUITY-SUSL의 가중치가 증가한 독특한 행동은 특정 시장 역학과 통화 변동에 기인할 수 있습니다. 미국 달러가 유로 대비 강세를 보이며 환율이 1.11305에서 1.0544로 하락한 것은 국제 투자자들에게 미국 기반 자산을 더 매력적으로 만들었을 가능성이 있으며, 이는 AA-ETF_EQUITY-SUSL의 가중치 증가를 설명할 수 있습니다 [Table 104]. 또한, Refinitiv 미국 정부 벤치마크 입찰 수익률 3년물이 4.277에서 4.237로 약간 감소한 것은 투자자들이 금리 기대 변화에 대응하여 포트폴리오를 조정하려 했음을 시사할 수 있습니다 [Table 102]. 이러한 요인은 투자 결정을 내릴 때 통화 움직임과 금리 추세를 고려하는 것의 중요성을 강조하며, 이는 다양한 자산 클래스의 상대적 매력에 크게 영향을 미치고 포트폴리오 할당에 영향을 미칠 수 있습니다.\\n\\n### 출처\\n\\n[Table 101], [Table 102], [Table 103], [Table 104].'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mi_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
